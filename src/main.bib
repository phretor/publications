@InProceedings{   unruh_joernphp_2017,
  shorttitle    = {JoernPHP},
  author        = {Unruh, Tommi and Shastry, Bhargava and Skoruppa, Malte and
                  Maggi, Federico and Rieck, Konrad and Seifert, Jean-Pierre
                  and Yamaguchi, Fabian},
  title         = {Leveraging Flawed Tutorials for Seeding Large-Scale Web
                  Vulnerability Discovery},
  publisher     = {{USENIX} Association},
  booktitle     = {Proceedings of the 11th {USENIX} Workshop on Offensive
                  Technologies ({WOOT} 17)},
  location      = {Vancouver, BC},
  abstract      = {The Web is replete with tutorial-style content on how to
                  accomplish programming tasks. Unfortunately, even top-ranked
                  tutorials suffer from severe security vulnerabilities, such
                  as cross-site scripting (XSS), and SQL injection (SQLi).
                  Assuming that these tutorials influence real-world software
                  development, we hypothesize that code snippets from popular
                  tutorials can be used to bootstrap vulnerability discovery at
                  scale. To validate our hypothesis, we propose a
                  semi-automated approach to find recurring vulnerabilities
                  starting from a handful of top-ranked tutorials that contain
                  vulnerable code snippets. We evaluate our approach by
                  performing an analysis of tens of thousands of open-source
                  web applications to check if vulnerabilities originating in
                  the selected tutorials recur. Our analysis framework has been
                  running on a standard PC, analyzed 64,415 PHP codebases
                  hosted on GitHub thus far, and found a total of 117
                  vulnerabilities that have a strong syntactic similarity to
                  vulnerable code snippets present in popular tutorials. In
                  addition to shedding light on the anecdotal belief that
                  programmers reuse web tutorial code in an ad hoc manner, our
                  study finds disconcerting evidence of insufficiently reviewed
                  tutorials compromising the security of open-source projects.
                  Moreover, our findings testify to the feasibility of
                  large-scale vulnerability discovery using poorly written
                  tutorials as a starting point.},
  date          = {2017-08},
  url           = {https://www.usenix.org/conference/woot17/workshop-program/presentation/unruh},
  keywords      = {workshop}
}

@InProceedings{   zarras_sqlbot_2017,
  shorttitle    = {SQLBot},
  author        = {Zarras, Apostolis and Maggi, Federico},
  title         = {Hiding Behind the Shoulders of Giants: Abusing Crawlers for
                  Indirect Web Attacks},
  publisher     = {{IEEE Computer Society}},
  booktitle     = {Proceedings of the {{15th Annual International Conference}}
                  on {{Privacy}}, {{Security}} and {{Trust}} ({{PST}})},
  pages         = {(to appear)},
  location      = {Calgary, Canada},
  abstract      = {It could be argued that without search engines, the web
                  would have never grown to the size that it has today. To
                  achieve maximum coverage and provide relevant results, search
                  engines employ large armies of autonomous crawlers that
                  continuously scour the web, following links, indexing
                  content, and collecting features that are then used to
                  calculate the ranking of each page. In this paper, we
                  describe how autonomous crawlers can be abused by attackers
                  to exploit vulnerabilities on thirdparty websites while
                  hiding the true origin of the attacks. Moreover, we show how
                  certain vulnerabilities on websites that are currently deemed
                  unimportant, can be abused in a way that would allow an
                  attacker to arbitrarily boost the rankings of malicious
                  websites in the search results of popular search engines.
                  Motivated by the potentials of these vulnerabilities, we
                  propose a series of preventive and defensive countermeasures
                  that website owners and search engines can adopt to minimize,
                  or altogether eliminate, the effects of crawler-abusing
                  attacks.},
  date          = {2017-08}
}

@InProceedings{   shastry_hybridstaticfuzzing_2017,
  shorttitle    = {HybridStaticFuzzing},
  author        = {Shastry, Bhargava and Maggi, Federico and Yamaguchi, Fabian
                  and Rieck, Konrad and Seifert, Jean-Pierre},
  title         = {Static Exploration of Taint-Style Vulnerabilities Found by
                  Fuzzing},
  publisher     = {{USENIX} Association},
  booktitle     = {11th {USENIX} Workshop on Offensive Technologies ({WOOT}
                  17)},
  location      = {Vancouver, BC},
  abstract      = {Taint-style vulnerabilities comprise a majority of fuzzer
                  discovered program faults. These vulnerabilities usually
                  manifest as memory access violations caused by tainted
                  program input. Although fuzzers have helped uncover a
                  majority of taint-style vulnerabilities in software to date,
                  they are limited by (i) extent of test coverage; and (ii) the
                  availability of fuzzable test cases. Therefore, fuzzing alone
                  cannot provide a high assurance that all taint-style
                  vulnerabilities have been uncovered.
                  
                  In this paper, we use static template matching to find
                  recurrences of fuzzer-discovered vulnerabilities. To
                  compensate for the inherent incompleteness of template
                  matching, we implement a simple yet effective match-ranking
                  algorithm that uses test coverage data to focus attention on
                  matches comprising untested code. We prototype our approach
                  using the Clang/LLVM compiler toolchain and use it in
                  conjunction with afl-fuzz, a modern coverage-guided fuzzer.
                  Using a case study carried out on the Open vSwitch codebase,
                  we show that our prototype uncovers corner cases in modules
                  that lack a fuzzable test harness. Our work demonstrates that
                  static analysis can effectively complement fuzz testing, and
                  is a useful addition to the security assessment tool-set.
                  Furthermore, our techniques hold promise for increasing the
                  effectiveness of program analysis and testing, and serve as a
                  building block for a hybrid vulnerability discovery
                  framework.},
  date          = {2017-08},
  url           = {https://www.usenix.org/conference/woot17/workshop-program/presentation/shastry},
  keywords      = {workshop}
}

@Unpublished{     balduzzi_defplorexbhus_talk_2017,
  shorttitle    = {DefPloreXBHUS},
  author        = {{Balduzzi, Marco and Maggi, Federico and Ciancaglini,
                  Vincenzo and Flores, Ryan and Gu, Lion}},
  title         = {DefPloreX: A Machine Learning Toolkit for Large-scale
                  e-Crime Forensics},
  eventtitle    = {{Black Hat Arsenal USA}},
  abstract      = {The security industry as a whole---including operation
                  centers, providers and telcos---loves collecting data.
                  Researchers are not different! A sort of common feeling is
                  that the more data someone collects, the more self-confident
                  he becomes about, say, a threat or another phenomenon.
                  However, large volumes of data imply more processing
                  resources needed, especially in extracting meaningful and
                  useful information if the data is highly unstructured. As a
                  result, manual data analysis is often the only choice, with
                  security professionals like pen-testers, reversers and
                  analysts processing data through tedious repetitive
                  operations.
                  
                  Given this situation, and our research lab suffering from
                  similar problems, we have spent the first half of 2017
                  implementing a flexible toolkit based on open-source
                  libraries for efficiently analyzing millions of deface pages
                  and web incidents. Our tool, DefPloreX, uses a combination of
                  machine-learning and visualization techniques to practically
                  turn original unstructured data into meaningful high-level
                  descriptions. Real-time information on incidents, breaches,
                  attacks and vulnerabilities, for example, are efficiently
                  processed and condensed into objects that are easily
                  browsable -- making them suitable for efficient large-scale
                  eCrime forensics and investigations.
                  
                  DefPloreX ingests plain CSV inputs about web incidents to
                  analyze, explores their resources with headless browsers,
                  extracts features from deface pages, and uploads the
                  resulting data to an Elastic index. Distributed headless
                  browsers are coordinated via Celery. Using Python Panda,
                  NumPy and PyTables, DefPloreX provides offline "views" of the
                  data, allowing easy pivoting and exploration. Our toolkit
                  automatically groups similar deface pages in clusters and
                  organizes web incidents in campaigns. Requiring only one
                  pass, clustering is intrinsically parallel and not memory
                  bound. DefPloreX offers text- and web-based UIs, which can be
                  queried using a simple language for investigations and
                  forensics.},
  location      = {Las Vegas, US},
  url           = {https://www.blackhat.com/us-17/arsenal.html#defplorex-a-machine-learning-toolkit-for-large-scale-ecrime-forensics},
  date          = {2017-07-27},
  howpublished  = {Peer-reviewed Demo}
}

@Unpublished{     continella_shieldfsbhus_talk_2017,
  shorttitle    = {ShieldFSBHUS},
  author        = {{Continella, Andrea and Guagnelli, Alessandro and Zingaro,
                  Giovanni and De Pasquale, Giulio and Barenghi, Alessandro and
                  Zanero, Stefano and Maggi, Federico}},
  title         = {ShieldFS: The Last Word in Ransomware-resilient File
                  Systems},
  eventtitle    = {{Black Hat Briefings USA}},
  abstract      = {Preventive and reactive security measures can only partially
                  mitigate the damage caused by modern ransomware attacks. The
                  remarkable amount of illicit profit and the cybercriminals'
                  increasing interest in ransomware schemes demonstrate that
                  current defense solutions are failing, and a large number of
                  users are actually paying the ransoms. In fact,
                  pure-detection approaches (e.g., based on analysis sandboxes
                  or pipelines) are not sufficient, because, when luck allows a
                  sample to be isolated and analyzed, it is already too late
                  for several users! Moreover, modern ransomware implements
                  several techniques to prevent detection by common AV.
                  Similarly, for performance reasons, backups leave a
                  small-but-important window of recent files unprotected.
                  
                  We believe that a forward-looking solution is to equip modern
                  operating systems with generic, practical self-healing
                  capabilities against this serious threat.
                  
                  In this talk, we will present ShieldFS, a drop-in driver that
                  makes the Windows native filesystem immune to ransomware
                  attacks, even when detection fails ShieldFS dynamically
                  toggles a protection layer that acts as a copy-on-write
                  mechanism whenever its detection component reveals suspicious
                  activity. For this, ShieldFS monitors the filesystem's
                  internals to update a set of adaptive models that profile the
                  system activity over time. This detection is based on a study
                  of the filesystem activity of over 2,245 applications, and
                  takes into account the entropy of write operations, frequency
                  of read, write, and folder-listing operations, fraction of
                  files renamed, and the file-type usage statistics.
                  Additionally, ShieldFS monitors the memory pages of each
                  "potentially malicious" process, searching for traces of the
                  typical block cipher key schedules.
                  
                  We will show how ShieldFS can shadow the write operations.
                  Whenever one or more processes violate our detection
                  component, their operations are deemed malicious and the side
                  effects on the filesystem are transparently rolled back.
                  
                  Last, we will demo how effective ShieldFS is against samples
                  from state of the art ransomware families, showing that it is
                  able to detect the malicious activity at runtime and
                  transparently recover all the original files.},
  location      = {Las Vegas, US},
  url           = {https://www.blackhat.com/us-17/briefings.html#shieldfs-the-last-word-in-ransomware-resilient-file-systems},
  date          = {2017-07-27},
  howpublished  = {Peer-reviewed Talk}
}

@Unpublished{     quarta_robosecbhus_talk_2017,
  shorttitle    = {RoboSecBHUS},
  author        = {{Quarta, Davide and Pogliani, Marcello and Polino, Mario and
                  Maggi, Federico and Zanero Stefano}},
  title         = {Breaking the Laws of Robotics: Attacking Industrial Robots},
  eventtitle    = {{Black Hat Briefings USA}},
  abstract      = {Industrial robots are complex cyber-physical systems used
                  for manufacturing, and a critical component of any modern
                  factory. These robots aren't just electromechanical devices
                  but include complex embedded controllers, which are often
                  interconnected with other computers in the factory network,
                  safety systems, and to the Internet for remote monitoring and
                  maintenance. In this scenario, industrial routers also play a
                  key role, because they directly expose the robot's
                  controller. Therefore, the impact of a single, simple
                  vulnerability can grant attackers an easy entry point.
                  
                  Industrial robots must follow three fundamental laws:
                  accurately "read" from the physical world through sensors and
                  "write" (i.e. perform actions) through actuators, refuse to
                  execute self-damaging control logic, and most importantly,
                  echoing Asimov, never harm humans. By combining a set of
                  vulnerabilities we discovered on a real robot, we will
                  demonstrate how remote attackers are able to violate such
                  fundamental laws up to the point where they can alter the
                  manufactured product, physically damage the robot, steal
                  industry secrets, or injure humans.
                  
                  We will cover in-depth technical aspects (e.g., reverse
                  engineering and vulnerability details, and attack PoCs),
                  alongside a broader discussion on the security posture of
                  industrial routers and robots: Why these devices are
                  attractive for attackers? What could they achieve? Are they
                  hard to compromise? How can their security be improved?},
  location      = {Las Vegas, US},
  url           = {https://www.blackhat.com/us-17/briefings.html#breaking-the-laws-of-robotics-attacking-industrial-robots},
  date          = {2017-07-27},
  howpublished  = {Peer-reviewed Talk}
}

@InProceedings{   palanca_candos_2017,
  shorttitle    = {CANDoS},
  author        = {Palanca, Andrea and Evenchick, Eric and Maggi, Federico and
                  Zanero, Stefano},
  title         = {A Stealth, Selective, Link-Layer Denial-of-Service Attack
                  Against Automotive Networks},
  publisher     = {Springer International Publishing},
  editor        = {Polychronakis, Michalis and Meier, Michael},
  booktitle     = {Proceedings of the 14th International Conference on
                  Detection of Intrusions and Malware, and Vulnerability
                  Assessment (DIMVA)},
  pages         = {185--206},
  location      = {Bonn, Germany},
  abstract      = {Modern vehicles incorporate tens of electronic control units
                  (ECUs), driven by as much as 100,000,000 lines of code. They
                  are tightly interconnected via internal networks, mostly
                  based on the CAN bus standard. Past research showed that, by
                  obtaining physical access to the network or by remotely
                  compromising a vulnerable ECU, an attacker could control even
                  safety-critical inputs such as throttle, steering or brakes.
                  In order to secure current CAN networks from cyberattacks,
                  detection and prevention approaches based on the analysis of
                  transmitted frames have been proposed, and are generally
                  considered the most time- and cost-effective solution, to the
                  point that companies have started promoting aftermarket
                  products for existing vehicles.},
  doi           = {10.1007/978-3-319-60876-1_9},
  isbn          = {978-3-319-60876-1},
  date          = {2017-07-06}
}

@InProceedings{   quarta_robosec_2017,
  shorttitle    = {RoboSec},
  author        = {Quarta, Davide and Pogliani, Marcello and Polino, Mario and
                  Maggi, Federico and Zanchettin, Andrea Maria and Zanero,
                  Stefano},
  title         = {An Experimental Security Analysis of an Industrial Robot
                  Controller},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the 38th {IEEE} Symposium on Security and
                  Privacy},
  series        = {S\&P '17},
  location      = {San Jose, CA},
  abstract      = {Industrial robots, automated manufacturing, and efficient
                  logistics processes are at the heart of the upcoming fourth
                  industrial revolution. While there are seminal studies on the
                  vulnerabilities of cyber-physical systems in the industry, as
                  of today there has been no systematic analysis of the
                  security of industrial robot controllers. We examine the
                  standard architecture of an industrial robot and analyze a
                  concrete deployment from a systems security standpoint. Then,
                  we propose an attacker model and confront it with the minimal
                  set of requirements that industrial robots should honor:
                  precision in sensing the environment, correctness in
                  execution of control logic, and safety for human operators.
                  Following an experimental and practical approach, we then
                  show how our modeled attacker can subvert such requirements
                  through the exploitation of software vulnerabilities, leading
                  to severe consequences that are unique to the robotics
                  domain. We conclude by discussing safety standards and
                  security challenges in industrial robotics.},
  doi           = {10.1109/SP.2017.20},
  date          = {2017-05}
}

@InProceedings{   continella_shieldfs_2016,
  shorttitle    = {ShieldFS},
  author        = {Continella, Andrea and Guagnelli, Alessandro and Zingaro,
                  Giovanni and De Pasquale, Giulio and Barenghi, Alessandro and
                  Zanero, Stefano and Maggi, Federico},
  title         = {{ShieldFS}: A Self-healing, Ransomware-aware Filesystem},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the 32nd {{Annual Computer Security
                  Applications Conference}}},
  series        = {ACSAC '16},
  pages         = {336--347},
  location      = {{Los Angeles, USA}},
  abstract      = {Preventive and reactive security measures can only partially
                  mitigate the damage caused by modern ransomware attacks.
                  Indeed, the remarkable amount of illicit profit and the
                  cybercriminals’ increasing interest in ransomware schemes
                  suggest that a fair number of users are actually paying the
                  ransoms. Unfortunately, pure-detection approaches (e.g.,
                  based on analysis sandboxes or pipelines) are not sufficient
                  nowadays, because often we do not have the luxury of being
                  able to isolate a sample to analyze, and when this happens it
                  is already too late for several users! We believe that a
                  forwardlooking solution is to equip modern operating systems
                  with practical self-healing capabilities against this serious
                  threat. Towards such a vision, we propose ShieldFS, an add-on
                  driver that makes the Windows native filesystem immune to
                  ransomware attacks. For each running process, ShieldFS
                  dynamically toggles a protection layer that acts as a
                  copy-onwrite mechanism, according to the outcome of its
                  detection component. Internally, ShieldFS monitors the
                  low-level filesystem activity to update a set of adaptive
                  models that profile the system activity over time. Whenever
                  one or more processes violate these models, their operations
                  are deemed malicious and the side effects on the filesystem
                  are transparently rolled back.
                  
                  We designed ShieldFS after an analysis of billions of
                  low-level, I/O filesystem requests generated by thousands of
                  benign applications, which we collected from clean machines
                  in use by real users for about one month. This is the first
                  measurement on the filesystem activity of a large set of
                  benign applications in real working conditions. We evaluated
                  ShieldFS in real-world working conditions on real, personal
                  machines, against samples from state of the art ransomware
                  families. ShieldFS was able to detect the malicious activity
                  at runtime and transparently recover all the original files.
                  Although the models can be tuned to fit various filesystem
                  usage profiles, our results show that our initial tuning
                  yields high accuracy even on unseen samples and variants.},
  doi           = {10.1145/2991079.2991110},
  isbn          = {978-1-4503-4771-6},
  numpages      = {12},
  date          = {2016-12}
}

@Unpublished{     mavroudis_silverdogbh_talk_2016,
  shorttitle    = {SilverDogBH},
  author        = {{Mavroudis, Vasilios and Hao, Shuang and Fratantonio, Yanick
                  and Maggi, Federico and Vigna, Giovanni and Kruegel,
                  Christopher}},
  title         = {Talking Behind Your Back: Attacks and Countermeasures of
                  Ultrasonic Cross-Device Tracking},
  eventtitle    = {{Black Hat Briefings Europe}},
  abstract      = {Cross-device tracking (XDT) technologies are currently the
                  ``Holy Grail'' for marketers because they allow to track the
                  user's visited content across different devices to then push
                  relevant, more targeted content. For example, if a user
                  clicks on a particular advertisement while browsing the web
                  at home, the advertisers are very interested in collecting
                  this information to display, later on, related advertisements
                  on other devices belonging to the same user (e.g., phone,
                  tablet).
                  
                  Currently, the most recent innovation in this area is
                  ultrasonic cross-device tracking (uXDT), which is the use of
                  the ultrasonic spectrum as a communication channel to "pair"
                  devices for the aforementioned tracking purposes.
                  Technically, this pairing happens through a receiver
                  application installed on the phone or tablet. The business
                  model is that users will receive rewards or useful services
                  for keeping those apps active, pretty much like it happens
                  for proximity-marketing apps (e.g., Shopkick), where users
                  receive deals for walk-ins recorded by their
                  indoor-localizing apps.
                  
                  This talk will describe and demonstrate the practical
                  security and privacy risks that arise with the adoption of
                  uXDT-enabled systems. The uXDT technology has caught the
                  attention of major companies (e.g., IDG Ventures, Google,
                  Nestle, Dominos), many of which either invested in uXDT
                  providers (e.g., SilverPush, Signal360, Audible Magic), or
                  approached such companies as clients. Unfortunately,
                  unbeknownst to the users, we found that numerous mobile
                  applications, some with millions of downloads, include uXDT
                  advertising frameworks that actively listen for ultrasounds,
                  with no opt-out option for the users! Security experts and
                  the authorities (e.g., the Federal Trade Commission) have
                  promptly raised concerns about uXDT, but until now no
                  comprehensive security analysis of the technology has been
                  released.
                  
                  In this talk, we will explore the uXDT ecosystem, dig into
                  the inner workings of popular uXDT frameworks, and perform an
                  in-depth technical analysis of the underlying technology,
                  exposing both implementation \& design vulnerabilities, and
                  critical security \& privacy shortcomings that we discovered.
                  In the offensive part of our talk, we will demonstrate
                  (through practical demo sessions) how an attacker can exploit
                  uXDT frameworks to reveal the true IP addresses of users who
                  browse the Internet through anonymity networks (e.g., VPNs or
                  Tor). Moreover, we will describe how an attacker can tamper
                  with the "pairing" process or affect the results of the
                  advertising/bidding algorithms. For example, an attacker
                  equipped with a simple beacon-emitting device (e.g., a
                  smartphone) can walk into a Starbucks at peak hour and launch
                  a profile-corruption attack against all customers currently
                  taking advantage of uXDT-enabled apps.
                  
                  In the defensive part of our talk, we will introduce three
                  countermeasures that we designed, implemented, and will
                  publicly release. These include (1) a mobile application that
                  detects ultrasound beacons "in the air" with the goal of
                  raising awareness, (2) a browser extension that acts as a
                  personal firewall by selectively filtering ultrasonic
                  beacons, and (3) an brand-new OS permission control in
                  Android that allows applications to declaratively ask access
                  to the ultrasound spectrum. We will go into the technical
                  details and provide remediation advice useful both for the
                  users and developers.},
  location      = {London, UK},
  url           = {https://www.blackhat.com/eu-16/briefings.html},
  date          = {2016-11-03},
  howpublished  = {Peer-reviewed Talk}
}

@Unpublished{     maggi_greateatlonbheu_talk_2016,
  shorttitle    = {GreatEatlonBHEU},
  author        = {Maggi, Federico and Zanero, Stefano},
  title         = {{Pocket-sized Badness: Why Ransomware Comes as a Plot Twist
                  in the Cat-Mouse Game}},
  eventtitle    = {{Black Hat Briefings Europe}},
  abstract      = {While we have grown accustomed to stealthy malware,
                  specifically written to gain and maintain control of the
                  victim machines to abuse their resources, ransomware really
                  comes as a "plot twist"! After 10+ years of stealthy malware,
                  spread mainly for building botnets and steal information, for
                  the second time we're witnessing a growth of disruptive
                  malware, and an interest for direct and fast profit.
                  Ransomware is a particularly striking example of disruptive
                  malware, both on mobile and desktop targets: While
                  traditional mass malware must fly under the radar to fulfill
                  its goals, a ransomware attack that remains unaccountable has
                  failed miserably. It must show up to inform and frighten the
                  victim! As a result, the human psychological response to the
                  attack plays a significant role in the success of ransomware
                  schemes. And, given the remarkable revenue, the scheme seems
                  to be working fairly well.
                  
                  This talk will describe the technical impact of disruptive
                  malware and its game-changing approach, which made us (at
                  least) rethink our incident-response plans. We will focus on
                  mobile ransomware as a representative, extreme case study.
                  Albeit not very studied, we are currently tracking 10
                  distinct families, and collected tenths of thousands distinct
                  samples in three months. In this talk, we will go through the
                  most notorious families such as Koler, SLocker, Svpeng (and
                  mention the other notable ones), overviewing their
                  social-engineering tricks and how they are technically
                  implemented. This will include, for instance, how an app can
                  effectively lock a device to forcefully display the typical
                  threatening message that informs the victim of what just
                  happened, or how crypto and file-system APIs are (ab)used to
                  surreptitiously encrypt the valuable data.
                  
                  After having overviewed these aspects, we will describe how
                  they can be effectively detected with specific static
                  features. We will present a lightweight Smali emulator to
                  track the instruction sequences that implement device-locking
                  mechanisms. To detect malicious encryption attempts, we will
                  present a static, dataflow-based program-analysis technique
                  and tool that track file-system operations (e.g., file
                  listing, file reading) to determine if they are "connected"
                  to encryption flows. Since the most recent families have
                  started to abuse the device-administration API (e.g., to lock
                  the device), obfuscated method names and reflection to hinder
                  automatic static analysis, we will show a couple of
                  counter-tricks. Last, we will show how the threatening
                  messages can be recognized from normal text using a
                  language-analysis technique, which classifies text based on
                  the appearance of key terms frequently found in ransomware
                  samples but not in benign sources. Since static
                  program-analysis approaches like ours can be time and
                  resource consuming, we describe a fast triaging pre-filtering
                  technique to quickly discard strikingly benign applications.
                  This filter is generic and ransomware-agnostic. Thus, in
                  principle, it could be applied to any app-vetting pipeline.
                  
                  With this talk we will release the source code of a prototype
                  that implements (part of) the described techniques, and a
                  dataset comprising tenths of thousands of ransomware
                  applications targeting the Android platform, each labeled
                  with the set of features that characterize their
                  statically-extracted behavior.},
  location      = {London, UK},
  url           = {https://www.blackhat.com/eu-16/briefings.html},
  date          = {2016-11-03},
  howpublished  = {Peer-reviewed Talk}
}

@InProceedings{   zheng_greateatlon_2016,
  shorttitle    = {GreatEatlon},
  author        = {Zheng, Chenghyu and Della Rocca, Nicola and Andronio,
                  Niccolò and Zanero, Stefano and Maggi Federico},
  title         = {GreatEatlon: Fast, Static Detection of Mobile Ransomware},
  pages         = {617--636},
  location      = {Guangzhou, People's Republic of China},
  abstract      = {Ransomware is a class of malware that aim at preventing
                  victims from accessing valuable data, typically via data
                  encryption or device locking, and ask for a payment to
                  release the target. In the past year, instances of ransomware
                  attacks have been spotted on mobile devices too. However,
                  despite their relatively low infection rate, we notice that
                  the techniques used by mobile ransomware are quite
                  sophisticated, and different from those used by ransomware
                  against traditional computers.
                  
                  Through an in-depth analysis of about 100 samples of
                  currently active ransomware apps, we conclude that most of
                  them pass undetected by state-of-the-art tools, which are
                  unable to recognize the abuse of benign features for
                  malicious purposes. The main reason is that such tools rely
                  on an inadequate and incomplete set of features. The most
                  notable examples are the abuse of reflection and
                  device-administration APIs, appearing in modern ransomware to
                  evade analysis and detection, and to elevate their privileges
                  (e.g., to lock or wipe the device). Moreover, current
                  solutions introduce several false positives in the na ̈ıve
                  way they detect cryptographic-APIs abuse, flagging goodware
                  apps as ransomware merely because they rely on cryptographic
                  libraries. Last but not least, the performance overhead of
                  current approaches is unacceptable for appstore-scale
                  workloads.
                  
                  In this work, we tackle the aforementioned limitations and
                  propose GreatEatlon, a next-generation mobile ransomware
                  detector. We foresee GreatEatlon deployed on the appstore
                  side, as a preventive countermeasure. At its core,
                  GreatEatlon uses static program-analysis techniques to
                  ``resolve'' reflection-based, anti-analysis attempts, to
                  recognize abuses of the device administration API, and
                  extract accurate data-flow information required to detect
                  truly malicious uses of cryptographic APIs. Given the
                  significant resources utilized by Great- Eatlon, we prepend
                  to its core a fast pre-filter that quickly discards obvious
                  goodware, in order to avoid wasting computer cycles.
                  
                  We tested GreatEatlon on thousands of samples of goodware,
                  generic malware and ransomware applications, and showed that
                  it surpasses current approaches both in speed and detection
                  capabilities, while keeping the false negative rate below
                  1.3\%. },
  doi           = {10.1007/978-3-319-59608-2_34},
  isbn          = {978-3-319-59608-2},
  date          = {2016-10-10}
}

@InProceedings{   zheng_openst_2016,
  shorttitle    = {OpenST},
  author        = {Zheng, Chenghyu and Dalla Preda, Mila and Granjal, Jorge and
                  Zanero, Stefano and Maggi, Federico},
  title         = {On-{{Chip System Call Tracing}}: {{A Feasibility Study}} and
                  {{Open Prototype}}},
  booktitle     = {{{IEEE Conference}} on {{Communications}} and {{Network
                  Security}} ({{CNS}})},
  pages         = {73-81},
  location      = {{Philadelphia, US}},
  abstract      = {Several tools for program tracing and introspection exist.
                  These tools can be used to analyze potentially malicious or
                  untrusted programs. In this setting, it is important to
                  prevent that the target program determines whether it is
                  being traced or not. This is typically achieved by minimizing
                  the code of the introspection routines and any artifact or
                  side-effect that the program can leverage. Indeed, the most
                  recent approaches consist of lightly instrumented operating
                  systems or thin hypervisors running directly on bare metal.
                  
                  Following this research trend, we investigate the feasibility
                  of transparently tracing a Linux/ARM program without
                  modifying the software stack, while keeping the analysis cost
                  and flexibility compatible with state of the art emulation-
                  or bare-metal-based approaches. As for the typical program
                  tracing task, our goal is to reconstruct the stream of system
                  call invocations along with the respective un-marshalled
                  arguments.
                  
                  We propose to leverage the availability of on-chip debugging
                  interfaces of modern ARM systems, which are accessible via
                  JTAG. More precisely, we developed OpenST, an open-source
                  prototype tracer that allowed us to analyze the performance
                  overhead and to assess the transparency with respect to
                  evasive, real-world malicious programs. OpenST has two
                  tracing modes: In-kernel dynamic tracing and external
                  tracing. The in-kernel dynamic tracing mode uses the JTAG
                  interface to ``hot-patch'' the system calls at runtime,
                  injecting introspection code. This mode is more transparent
                  than emulator based approaches, but assumes that the traced
                  program does not have access to the kernel memory where the
                  introspection code is loaded. The external tracing mode
                  removes this assumption by using the JTAG interface to manage
                  hardware breakpoints.
                  
                  Our tests show that OpenST's greater transparency comes at
                  the price of a steep performance penalty. However, with a
                  cost model, we show that OpenST scales better than the state
                  of the art, bare-metal-based approach, while remaining
                  equally stealthy to evasive malware.},
  doi           = {10.1109/CNS.2016.7860472},
  date          = {2016-10}
}

@Article{         dalla-preda_aamo_article_2016,
  shorttitle    = {AAMO},
  author        = {Dalla Preda, Mila and Maggi, Federico},
  title         = {Testing android malware detectors against code obfuscation:
                  a systematization of knowledge and unified methodology},
  journal       = {Journal of Computer Virology and Hacking Techniques},
  pages         = {1--24},
  abstract      = {The authors of mobile-malware have started to leverage
                  program protection techniques to circumvent anti-viruses, or
                  simply hinder reverse engineering. In response to the
                  diffusion of anti-virus applications, several researches have
                  proposed a plethora of analyses and approaches to highlight
                  their limitations when malware authors employ
                  program-protection techniques. An important contribution of
                  this work is a systematization of the state of the art of
                  anti-virus apps, comparing the existing approaches and
                  providing a detailed analysis of their pros and cons. As a
                  result of our systematization, we notice the lack of openness
                  and reproducibility that, in our opinion, are crucial for any
                  analysis methodology. Following this observation, the second
                  contribution of this work is an open, reproducible, rigorous
                  methodology to assess the effectiveness of mobile anti-virus
                  tools against code-transformation attacks. Our unified
                  workflow, released in the form of an open-source prototype,
                  comprises a comprehensive set of obfuscation operators. It is
                  intended to be used by anti-virus developers and vendors to
                  test the resilience of their products against a large dataset
                  of malware samples and obfuscations, and to obtain insights
                  on how to improve their products with respect to particular
                  classes of code-transformation attacks.},
  doi           = {10.1007/s11416-016-0282-2},
  issn          = {2263-8733},
  url           = {http://dx.doi.org/10.1007/s11416-016-0282-2},
  date          = {2016-09-20}
}

@InProceedings{   mambretti_trellis_2016,
  shorttitle    = {Trellis},
  author        = {Mambretti, Andrea and Onarlioglu, Kaan and Mulliner, Collin
                  and Robertson, William and Kirda, Engin and Maggi, Federico
                  and Zanero, Stefano},
  title         = {Trellis: {{Privilege Separation}} for {{Multi-User
                  Applications Made Easy}}},
  booktitle     = {International {{Symposium}} on {{Research}} in {{Attacks}},
                  {{Intrusions}} and {{Defenses}} ({{RAID}})},
  pages         = {437--456},
  location      = {{Paris, France}},
  abstract      = {Operating systems provide a wide variety of resource
                  isolation and access control mechanisms, ranging from
                  traditional user-based security models to fine-grained
                  permission systems as found in modern mobile operating
                  systems. However, comparatively little assistance is
                  available for defining and enforcing access control policies
                  within multiuser applications. These applications, often
                  found in enterprise environments, allow multiple users to
                  operate at different privilege levels in terms of exercising
                  application functionality and accessing data. Developers of
                  such applications bear a heavy burden in ensuring that
                  security policies over code and data in this setting are
                  properly expressed and enforced. We present Trellis, an
                  approach for expressing hierarchical access control policies
                  in applications and enforcing these policies during
                  execution. The approach enhances the development toolchain to
                  allow programmers to partially annotate code and data with
                  simple privilege level tags, and uses a static analysis to
                  infer suitable tags for the entire application. At runtime,
                  policies are extracted from the resulting binaries and are
                  enforced by a modified operating system kernel. Our
                  evaluation demonstrates that this approach effectively
                  supports the development of secure multi-user applications
                  with modest runtime performance overhead.},
  doi           = {10.1007/978-3-319-45719-2_20},
  date          = {2016-09}
}

@Unpublished{     maggi_banksealer_talk_2016,
  shorttitle    = {BankSealer},
  author        = {Maggi, Federico},
  title         = {Fast and {{Transparent Online Banking Fraud Detection}} and
                  {{Investigation}}},
  eventtitle    = {Hek.si},
  location      = {{Ljubljana, Slovenia}},
  date          = {2016-04-15},
  howpublished  = {Invited Talk}
}

@InProceedings{   coletta_droydseuss_2016,
  shorttitle    = {DroydSeuss},
  author        = {Coletta, Alberto and Van der Veen, Victor and Maggi,
                  Federico},
  title         = {{{DroydSeuss}}: {{A Mobile Banking Trojan Tracker}} -
                  {{Short Paper}}},
  publisher     = {{Springer Berlin Heidelberg}},
  booktitle     = {Financial {{Cryptography}} and {{Data Security}}},
  series        = {Lecture Notes in Computer Science (LNCS)},
  abstract      = {After analyzing several Android mobile banking trojans, we
                  observed the presence of repetitive artifacts that describe
                  valuable information about the distribution of this class of
                  malicious apps. Motivated by the high threat level posed by
                  mobile banking trojans and by the lack of publicly available
                  analysis and intelligence tools, we automated the extraction
                  of such artifacts and created a malware tracker named
                  DroydSeuss. DroydSeuss first processes applications both
                  statically and dynamically, extracting relevant strings that
                  contain traces of communication endpoints. Second, it
                  prioritizes the extracted strings based on the APIs that
                  manipulate them. Finally, DroydSeuss correlates the endpoints
                  with descriptive metadata from the samples, providing
                  aggregated statistics, raw data, and cross-sample information
                  that allow researchers to pinpoint relevant groups of
                  applications. We connected DroydSeuss to the VirusTotal daily
                  feed, consuming Android samples that perform banking-trojan
                  activity. We manually analyzed its output and found
                  supporting evidence to confirm its correctness. Remarkably,
                  the most frequent itemset unveiled a campaign currently
                  spreading against Chinese and Korean bank customers.
                  
                  Although motivated by mobile banking trojans, DroydSeuss can
                  be used to analyze the communication behavior of any
                  suspicious application.},
  date          = {2016-02}
}

@InProceedings{   falsina_grabnrun_2015,
  shorttitle    = {GrabNRun},
  author        = {Falsina, Luca and Fratantonio, Yanick and Zanero, Stefano
                  and Kruegel, Christopher and Vigna, Giovanni and Maggi,
                  Federico},
  title         = {Grab 'n {{Run}}: {{Secure}} and {{Practical Dynamic Code
                  Loading}} for {{Android Applications}}},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the 31st {{Annual Computer Security
                  Applications Conference}}},
  series        = {ACSAC '15},
  pages         = {201--210},
  location      = {{Los Angeles, USA}},
  abstract      = {Android introduced the dynamic code loading (DCL) mechanism
                  to allow for code reuse, to achieve extensibility, to enable
                  updating functionalities or to boost application start- up
                  performance. In spite of its wide adoption by developers,
                  implementing DCL in a secure way is challenging, leading to
                  serious vulnerabilities such as remote code injection.
                  Previous academic and community attempts at solving this
                  problem are unfortunately either impractical or incomplete,
                  or in some cases exhibit vulnerabilities. In this paper, we
                  propose, design, implement and test Grab 'n Run, a novel code
                  verification protocol and a series of supporting libraries,
                  APIs, and components, that address the problem by abstracting
                  away from the developer challenging implementation details.
                  Grab 'n Run is designed to be practical: among its tools, it
                  provides a drop-in library, which requires no modifications
                  to the Android framework or the underlying Dalvik/ART
                  runtime, is very similar to the native API, and most code can
                  be automatically rewritten to use it. Grab 'n Run also
                  contains an application rewriting tool, which allows easy
                  porting of existing applications to use the secure API of its
                  library. We evaluate Grab 'n Run library with a user study,
                  obtaining impressive results in vulnerability reduction, ease
                  of use and speed of development. We also show that the
                  performance overhead introduced by our library is negligible.
                  The library is released as free software.},
  doi           = {10.1145/2818000.2818042},
  isbn          = {978-1-4503-3682-6},
  numpages      = {10},
  date          = {2015-12}
}

@Unpublished{     maggi_mobilemalware_talk_2015,
  shorttitle    = {MobileMalware},
  author        = {Maggi, Federico and Fratantonio, Yanick},
  title         = {Malware on {{Mobile}}: {{The What}}, {{The Why}}, and {{The
                  How}}},
  eventtitle    = {{Science and Engineering Council of Santa Barbara}},
  location      = {{Santa Barbara, CA}},
  date          = {2015-11-11},
  howpublished  = {Invited Talk}
}

@Article{         valdi_andrototal_article_2015,
  shorttitle    = {AndroTotal},
  author        = {Valdi, Andrea and Lever, Eros and Benefico, Simone and
                  Quarta, Davide and Zanero, Stefano and Maggi, Federico},
  title         = {Scalable {{Testing}} of {{Mobile Antivirus Applications}}},
  journaltitle  = {Computer},
  volume        = {48},
  number        = {11},
  pages         = {60--68},
  abstract      = {AndroTotal, a scalable antivirus evaluation system for
                  mobile devices, creates reproducible, self-contained testing
                  environments for each antivirus application and malware pair
                  and stores them in a repository, benefiting both the research
                  community and Android device users.},
  doi           = {10.1109/MC.2015.320},
  issn          = {0018-9162},
  date          = {2015-11}
}

@InProceedings{   andronio_heldroid_2015,
  shorttitle    = {HelDroid},
  author        = {Andronio, Niccolò and Zanero, Stefano and Maggi, Federico},
  title         = {{HelDroid}: Dissecting and Detecting Mobile Ransomware},
  booktitle     = {International {{Symposium}} on {{Research}} in {{Attacks}},
                  {{Intrusions}} and {{Defenses}} ({{RAID}})},
  volume        = {9404},
  series        = {Lecture Notes in Computer Science},
  pages         = {382--404},
  location      = {Kyoto, Japan},
  abstract      = {In ransomware attacks, the actual target is the human, as
                  opposed to the classic attacks that abuse the infected
                  devices (e.g., botnet renting, information stealing). Mobile
                  devices are by no means immune to ransomware attacks.
                  However, there is little research work on this matter and
                  only traditional protections are available. Even
                  state-of-the-art mobile malware detection approaches are
                  ineffective against ransomware apps because of the subtle
                  attack scheme. As a consequence, the ample attack surface
                  formed by the billion mobile devices is left unprotected.
                  First, in this work we summarize the results of our analysis
                  of the existing mobile ransomware families, describing their
                  common characteristics. Second, we present HelDroid, a fast,
                  efficient and fully automated approach that recognizes known
                  and unknown scareware and ransomware samples from goodware.
                  Our approach is based on detecting the ``build- ing blocks''
                  that are typically needed to implement a mobile ransomware
                  application. Specifically, HelDroid detects, in a generic
                  way, if an app is attempting to lock or encrypt the device
                  without the user’s consent, and if ransom requests are
                  displayed on the screen. Our technique works without
                  requiring that a sample of a certain family is available
                  beforehand. We implemented HelDroid and tested it on
                  real-world Android ransomware samples. On a large dataset
                  comprising hundreds of thousands of APKs including goodware,
                  malware, scareware, and ransomware, HelDroid exhibited nearly
                  zero false positives and the capability of recognizing
                  unknown ransomware samples. },
  doi           = {10.1007/978-3-319-26362-5_18},
  date          = {2015-10}
}

@InProceedings{   ilia_faceoff_2015,
  shorttitle    = {FaceOff},
  author        = {Ilia, Panagiotis and Polakis, Iasonas and Athanasopoulos,
                  Elias and Maggi, Federico and Ioannidis, Sotiris},
  title         = {Face/{{Off}}: {{Preventing Privacy Leakage From Photos}} in
                  {{Social Networks}}},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the {{22Nd ACM SIGSAC Conference}} on
                  {{Computer}} and {{Communications Security}}},
  series        = {CCS '15},
  pages         = {781--792},
  location      = {{New York, NY, USA}},
  abstract      = {The capabilities of modern devices, coupled with the almost
                  ubiquitous availability of Internet connectivity, have
                  resulted in photos being shared online at an unprecedented
                  scale. This is further amplified by the popularity of social
                  networks and the immediacy they offer in content sharing.
                  Existing access control mechanisms are too coarse-grained to
                  handle cases of conflicting interests between the users
                  associated with a photo; stories of embarrassing or
                  inappropriate photos being widely accessible have become
                  quite common. In this paper, we propose to rethink access
                  control when applied to photos, in a way that allows us to
                  effectively prevent unwanted individuals from recognizing
                  users in a photo. The core concept behind our approach is to
                  change the granularity of access control from the level of
                  the photo to that of a user's personally identifiable
                  information (PII). In this work, we consider the face as the
                  PII. When another user attempts to access a photo, the system
                  determines which faces the user does not have the permission
                  to view, and presents the photo with the restricted faces
                  blurred out. Our system takes advantage of the existing face
                  recognition functionality of social networks, and can
                  interoperate with the current photo-level access control
                  mechanisms. We implement a proof-of-concept application for
                  Facebook, and demonstrate that the performance overhead of
                  our approach is minimal. We also conduct a user study to
                  evaluate the privacy offered by our approach, and find that
                  it effectively prevents users from identifying their contacts
                  in 87.35\% of the restricted photos. Finally, our study
                  reveals the misconceptions about the privacy offered by
                  existing mechanisms, and demonstrates that users are positive
                  towards the adoption of an intuitive, straightforward access
                  control mechanism that allows them to manage the visibility
                  of their face in published photos.},
  doi           = {10.1145/2810103.2813603},
  isbn          = {978-1-4503-3832-5},
  date          = {2015-10},
  url           = {http://doi.acm.org/10.1145/2810103.2813603}
}

@Unpublished{     maggi_droydseuss_talk_2015,
  shorttitle    = {DroydSeuss},
  author        = {Maggi, Federico},
  title         = {A walk through the construction of the first mobile malware
                  tracker},
  eventtitle    = {{Android Security Symposium}},
  location      = {{Vienna, Austria}},
  date          = {2015-09-11},
  url           = {https://usmile.at/symposium/program},
  howpublished  = {Invited Talk}
}

@InProceedings{   polino_jackdaw_2015,
  shorttitle    = {Jackdaw},
  author        = {Polino, Mario and Scorti, Andrea and Maggi, Federico and
                  Zanero, Stefano},
  title         = {Jackdaw: {{Towards Automatic Reverse Engineering}} of
                  {{Large Datasets}} of {{Binaries}}},
  publisher     = {{Springer International Publishing}},
  editor        = {Almgren, Magnus and Gulisano, Vincenzo and Maggi, Federico},
  booktitle     = {Detection of {{Intrusions}} and {{Malware}}, and
                  {{Vulnerability Assessment}}},
  series        = {Lecture Notes in Computer Science},
  pages         = {121--143},
  abstract      = {When analyzing an untrusted binary, reverse engineers
                  usually rely on ad-hoc collections of interesting dynamic
                  patterns known as behaviors in the malware-analysis community
                  and static patterns known as signatures in the antivirus
                  community. Such patterns are often part of the skill set of
                  the analyst, sometimes implemented in manually-created
                  post-processing scripts. It would be desirable to be able to
                  automatically find such behaviors, present them to analysts,
                  and create a systematic catalog of matching rules and
                  relevant implementations. We propose Jackdaw, a system that
                  finds interesting dynamic patterns, and ranks them to unveil
                  potentially interesting behaviors. Then, it annotates them
                  with static information, capturing the distinct
                  implementations of each across different malware families.
                  Finally, Jackdaw associates semantic information to the
                  behaviors, so as to create a descriptive summary that helps
                  the analysts in querying the catalog of behaviors by type. To
                  do this, it leverages the dynamic information and an indexed
                  Web-based knowledge databases. We implement and demonstrate
                  Jackdaw on the Win32 API (even if the technique can be
                  generalized to any OS). On a dataset of 2,136 distinct
                  binaries, including both malicious and benign libraries and
                  executables, we compared the behaviors extracted
                  automatically against a ground truth of 44 behaviors created
                  manually by expert analysts. Jackdaw found 77.3\% of them and
                  was able to exclude spurious behaviors in 99.6\% cases. We
                  also discovered 466 novel behaviors, among which manual
                  exploration and review by expert reverse engineers revealed
                  interesting findings and confirmed the correctness of the
                  semantic tagging.},
  doi           = {10.1007/978-3-319-20550-2_7},
  isbn          = {978-3-319-20549-6 978-3-319-20550-2},
  date          = {2015-07-09},
  url           = {http://link.springer.com/chapter/10.1007/978-3-319-20550-2_7}
}

@Unpublished{     maggi_mobileransomware_talk_2015,
  shorttitle    = {MobileRansomware},
  author        = {Maggi, Federico},
  title         = {{Mobile Ransomware}},
  eventtitle    = {{6th National Conference on Cyber Warfare}},
  location      = {{Milano, Italy}},
  date          = {2015-06-03},
  url           = {http://www.infowar.it/},
  howpublished  = {Invited Talk}
}

@Unpublished{     maggi_cybercrimethreatanalysis_talk_2015,
  shorttitle    = {CybercrimeThreatAnalysis},
  author        = {Maggi, Federico},
  title         = {From {{Cybercrime}} to {{Threat Analysis}}},
  location      = {{Università degli Studi di Trento}},
  date          = {2015-04-20},
  howpublished  = {Invited Talk}
}

@Article{         carminati_banksealer_article_2015,
  shorttitle    = {BankSealer},
  author        = {Carminati, Michele and Caron, Roberto and Maggi, Federico
                  and Epifani, Ilenia and Zanero, Stefano},
  title         = {{{BankSealer}}: {{A}} decision support system for online
                  banking fraud analysis and investigation},
  journaltitle  = {Computers \& Security},
  abstract      = {The significant growth of online banking frauds, fueled by
                  the underground economy of malware, raised the need for
                  effective fraud analysis systems. Unfortunately, almost all
                  of the existing approaches adopt black box models and
                  mechanisms that do not give any justifications to analysts.
                  Also, the development of such methods is stifled by limited
                  Internet banking data availability for the scientific
                  community. In this paper we describe BankSealer, a decision
                  support system for online banking fraud analysis and
                  investigation. During a training phase, BankSealer builds
                  easy-to-understand models for each customer's spending
                  habits, based on past transactions. First, it quantifies the
                  anomaly of each transaction with respect to the customer
                  historical profile. Second, it finds global clusters of
                  customers with similar spending habits. Third, it uses a
                  temporal threshold system that measures the anomaly of the
                  current spending pattern of each customer, with respect to
                  his or her past spending behavior. With this threefold
                  profiling approach, it mitigates the under-training due to
                  the lack of historical data for building well-trained
                  profiles, and the evolution of users' spending habits over
                  time. At runtime, BankSealer supports analysts by ranking new
                  transactions that deviate from the learned profiles, with an
                  output that has an easily understandable, immediate
                  statistical meaning.
                  
                  Our evaluation on real data, based on fraud scenarios built
                  in collaboration with domain experts that replicate typical,
                  real-world attacks (e.g., credential stealing, banking trojan
                  activity, and frauds repeated over time), shows that our
                  approach correctly ranks complex frauds. In particular, we
                  measure the effectiveness, the computational resource
                  requirements and the capabilities of BankSealer to mitigate
                  the problem of users that performed a low number of
                  transactions. Our system ranks frauds and anomalies with up
                  to 98\% detection rate and with a maximum daily computation
                  time of 4~min. Given the good results, a leading Italian bank
                  deployed a version of BankSealer in their environment to
                  analyze frauds.},
  doi           = {10.1016/j.cose.2015.04.002},
  issn          = {0167-4048},
  date          = {2015-04},
  url           = {http://www.sciencedirect.com/science/article/pii/S0167404815000437},
  shortjournal  = {Computers \& Security}
}

@Unpublished{     maggi_threatanalysis_talk_2015,
  shorttitle    = {ThreatAnalysis},
  author        = {Maggi, Federico},
  title         = {From {{Cybercrime}} to {{Threat Analysis}}},
  eventtitle    = {{Catedra Europa}},
  date          = {2015-03-18},
  url           = {http://www.uninorte.edu.co/web/catedra-europa},
  howpublished  = {Invited Talk}
}

@TechReport{      maggi_eusyssec_tr_2015,
  shorttitle    = {EUSysSec},
  author        = {Maggi, Federico and Zanero, Stefano and Markatos,
                  Evangelos},
  title         = {European {{Cyber-Security Research}} and {{Innovation}}},
  number        = {43},
  abstract      = {Looking back at the evolution of cyber criminal activities,
                  from the nineties to the present day, we observe interesting
                  trends coming together in what may seem a perfectly
                  orchestrated scene. In parallel with the `security by
                  design', we recall the importance of reactive security in a
                  field of ever-changing arms races.},
  date          = {2015-01},
  url           = {http://ercim-news.ercim.eu/en100/r-i/european-cyber-security-research-and-innovation},
  series        = {ERCIM News},
  pages         = {43}
}

@InProceedings{   polakis_resoauth_2014,
  shorttitle    = {ReSoAuth},
  author        = {Polakis, Iasonas and Ilia, Panagiotis and Maggi, Federico
                  and Lancini, Marco and Kontaxis, Georgios and Zanero, Stefano
                  and Ioannidis, Sotiris and Keromytis, Angelos D.},
  title         = {Faces in the {{Distorting Mirror}}: {{Revisiting
                  Photo}}-based {{Social Authentication}}},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the 2014 {{ACM SIGSAC Conference}} on
                  {{Computer}} and {{Communications Security}}},
  series        = {CCS '14},
  pages         = {501--512},
  location      = {{New York, NY, USA}},
  abstract      = {In an effort to hinder attackers from compromising user
                  accounts, Facebook launched a form of two-factor
                  authentication called social authentication (SA), where users
                  are required to identify photos of their friends to complete
                  a log-in attempt. Recent research, however, demonstrated that
                  attackers can bypass the mechanism by employing face
                  recognition software. Here we demonstrate an alternative
                  attack. that employs image comparison techniques to identify
                  the SA photos within an offline collection of the users'
                  photos. In this paper, we revisit the concept of SA and
                  design a system with a novel photo selection and
                  transformation process, which generates challenges that are
                  robust against these attacks. The intuition behind our photo
                  selection is to use photos. that fail software-based face
                  recognition, while remaining recognizable to humans who are
                  familiar with the depicted people. The photo transformation
                  process. creates challenges in the form of photo collages,
                  where faces are transformed so as to render image matching
                  techniques ineffective. We experimentally confirm the
                  robustness of our approach against three template. matching
                  algorithms that solve 0.4 percent of the challenges, while
                  requiring four orders of magnitude more processing effort.
                  Furthermore, when the transformations are applied, face
                  detection software fails to detect even a single face. Our
                  user studies confirm that users are able to identify their
                  friends in over 99\% of the photos with faces unrecognizable
                  by software, and can solve over 94 percent of the challenges
                  with transformed photos.},
  doi           = {10.1145/2660267.2660317},
  isbn          = {978-1-4503-2957-6},
  date          = {2014-11},
  url           = {http://doi.acm.org/10.1145/2660267.2660317}
}

@TechReport{      bazzoli_xsspeeker_tr_2014,
  shorttitle    = {XSSPeeker},
  author        = {Bazzoli, Enrico and Criscione, Claudio and Maggi, Federico
                  and Zanero, Stefano},
  title         = {{{XSS Peeker}}: {{A Systematic Analysis}} of {{Cross}}-site
                  {{Scripting Vulnerability Scanners}}},
  institution   = {{arXiv}},
  abstract      = {Since the first publication of the "OWASP Top 10" (2004),
                  cross-site scripting (XSS) vulnerabilities have always been
                  among the top 5 web application security bugs. Black-box
                  vulnerability scanners are widely used in the industry to
                  reproduce (XSS) attacks automatically. In spite of the
                  technical sophistication and advancement, previous work
                  showed that black-box scanners miss a non-negligible portion
                  of vulnerabilities, and report non-existing, non-exploitable
                  or uninteresting vulnerabilities. Unfortunately, these
                  results hold true even for XSS vulnerabilities, which are
                  relatively simple to trigger if compared, for instance, to
                  logic flaws. Black-box scanners have not been studied in
                  depth on this vertical: knowing precisely how scanners try to
                  detect XSS can provide useful insights to understand their
                  limitations, to design better detection methods. In this
                  paper, we present and discuss the results of a detailed and
                  systematic study on 6 black-box web scanners (both
                  proprietary and open source) that we conducted in
                  coordination with the respective vendors. To this end, we
                  developed an automated tool to (1) extract the payloads used
                  by each scanner, (2) distill the "templates" that have
                  originated each payload, (3) evaluate them according to
                  quality indicators, and (4) perform a cross-scanner analysis.
                  Unlike previous work, our testbed application, which contains
                  a large set of XSS vulnerabilities, including DOM XSS, was
                  gradually retrofitted to accomodate for the payloads that
                  triggered no vulnerabilities. Our analysis reveals a highly
                  fragmented scenario. Scanners exhibit a wide variety of
                  distinct payloads, a non-uniform approach to fuzzing and
                  mutating the payloads, and a very diverse detection
                  effectiveness.},
  date          = {2014-10-15},
  url           = {http://arxiv.org/abs/1410.4207}
}

@Unpublished{     maggi_cybercrime_talk_2014,
  shorttitle    = {Cybercrime},
  author        = {Maggi, Federico},
  title         = {Current and {{Future Cybercrime Tactics}}},
  eventtitle    = {{5th National Conference on Cyber Warfare}},
  location      = {{Milano, Italy}},
  date          = {2014-10-13},
  url           = {http://www.infowar.it/past/2014_october/index.php},
  howpublished  = {Invited Talk}
}

@Unpublished{     maggi_andradar_talk_2014,
  shorttitle    = {AndRadar},
  author        = {Maggi, Federico},
  title         = {Come to the {{Dark Side}}: {{We}} have {{Apps}}!},
  eventtitle    = {{HackInBo}},
  location      = {{Bologna, Italy}},
  date          = {2014-10-11},
  url           = {http://www.hackinbo.it/},
  howpublished  = {Invited Talk}
}

@Unpublished{     maggi_androidre_talk_2014,
  shorttitle    = {AndroidRe},
  author        = {Maggi, Federico},
  title         = {Static {{Analysis}} of {{Android Applications}}},
  eventtitle    = {{2nd SysSec Summer School}},
  location      = {{Amsterdam, The Netherlands}},
  date          = {2014-09-25},
  url           = {http://www.syssec-project.eu/events/summer-school-2014/program/},
  howpublished  = {Invited Lecture}
}

@InProceedings{   antonini_knxmalware_2014,
  shorttitle    = {KNXMalware},
  author        = {Antonini, Alessio and Maggi, Federico and Zanero, Stefano},
  title         = {A {{Practical Attack Against}} a {{KNX}}-based {{Building
                  Automation System}}},
  publisher     = {{BCS}},
  booktitle     = {Proceedings of the {{2Nd International Symposium}} on
                  {{ICS}} \& {{SCADA Cyber Security Research}} 2014},
  series        = {ICS-CSR 2014},
  pages         = {53--60},
  location      = {{UK}},
  abstract      = {Building automation systems rely heavily on general-purpose
                  computers and communication protocols, which are often
                  affected by security vulnerabilities. In this paper, we first
                  analyze the attack surface of a real building automation
                  system - based on the widely used KNX protocol-connected to a
                  general-purpose IP network. To this end, we analyze the
                  vulnerabilities of KNX-based networks highlighted by previous
                  research work, which, however, did not corroborate their
                  findings with experimental results. To verify the practical
                  exploitability of these vulnerabilities and their potential
                  impact, we implement a full-fledged testbed infrastructure
                  that reproduces the typical deployment of a building
                  automation system. On this testbed, we show the feasibility
                  of a practical attack that leverages and combines the
                  aforementioned vulnerabilities. We show the ease of reverse
                  engineering the vendor-specific components of the KNX
                  protocol. Our attack leverages the IP-to-KNX connectivity to
                  send arbitrary commands which are executed by the actuators.
                  We conclude that the vulnerabilities highlighted by previous
                  work are effectively exploitable in practice, with severe
                  results. Although we use KNX as a target, our work can be
                  generalized to other communication protocols, often
                  characterized by similar issues. Finally, we analyze the
                  countermeasures proposed in previous literature and reveal
                  the limitations that prevent their adoption in practice. We
                  suggest a practical stopgap measure to protect real KNX-based
                  BASs from our attack.},
  doi           = {10.14236/ewic/ics-csr2014.7},
  isbn          = {978-1-78017-286-6},
  date          = {2014-09},
  url           = {http://dx.doi.org/10.14236/ewic/ics-csr2014.7}
}

@InProceedings{   polakis_osnresearch_2014,
  shorttitle    = {OSNResearch},
  author        = {Polakis, Iasonas and Maggi, Federico and Zanero, Stefano and
                  Keromytis, Angelos D.},
  title         = {Security and {{Privacy Measurements}} on {{Social
                  Networks}}: {{Experiences}} and {{Lessons Learned}}},
  booktitle     = {2014 Third International Workshop on Building Analysis
                  Datasets and Gathering Experience Returns for Security
                  (BADGERS)},
  pages         = {18-29},
  location      = {{Wroclaw, Poland}},
  abstract      = {We describe our experience gained while exploring practical
                  security and privacy problems in a real-world, large- scale
                  social network (i.e., Facebook), and summarize our
                  conclusions in a series of "lessons learned". We first
                  conclude that it is better to adequately describe the
                  potential ethical concerns from the very beginning and plan
                  ahead the institutional review board (IRB) request. Even
                  though sometimes optional, the IRB approval is a valuable
                  point from the reviewer's perspective. Another aspect that
                  needs planning is getting in touch with the online social
                  network security team, which takes a substantial amount of
                  time. With their support, "bending the rules" (e.g., using
                  scrapers) when the experimental goals require so, is easier.
                  Clearly, in cases where critical technical vulnerabilities
                  are found during the research, the general recommendations
                  for responsible disclosure should be followed. Gaining the
                  audience's engagement and trust was essential to the success
                  of our user study. Participants felt more comfortable when
                  subscribing to our experiments, and also responsibly reported
                  bugs and glitches. We did not observe the same behavior in
                  crowd-sourcing workers, who were instead more interested in
                  obtaining their rewards. On a related point, our experience
                  suggests that crowd sourcing should not be used alone:
                  Setting up tasks is more time consuming than it seems, and
                  researchers must insert some sentinel checks to ensure that
                  workers are not submitting random answers.From a logistics
                  point of view, we learned that having at least a high-level
                  plan of the experiments pays back, especially when the IRB
                  requires a detailed description of the work and the data to
                  be collected. However, over planning can be dangerous because
                  the measurement goals can change dynamically. From a
                  technical point of view, partially connected to the logistics
                  remarks, having a complex and large data-gathering and
                  analysis framework may be counterproductive in terms of
                  set-up a- d management overhead. From our experience we
                  suggest to choose simple technologies that scale up if needed
                  but, more importantly, can scale down. For example, launching
                  a quick query should be straightforward, and the frameworks
                  should not impose too much overhead for formulating it. We
                  conclude with a series of practical recommendations on how to
                  successfully collect data from online social networks (e.g.,
                  using techniques for network multipresence, mimicking user
                  behavior, and other crawling "tricks"') and avoid abusing the
                  online service, while gathering the data required by the
                  experiments.},
  doi           = {10.1109/BADGERS.2014.9},
  date          = {2014-09},
  keywords      = {workshop}
}

@Unpublished{     maggi_virtualization_talk_2014,
  shorttitle    = {Virtualization},
  author        = {Maggi, Federico},
  title         = {Virtualization},
  eventtitle    = {{5th Int. Summer School on Information Security and
                  Protection}},
  location      = {{Verona, Italy}},
  date          = {2014-07-27},
  url           = {http://issisp2014.di.univr.it/},
  howpublished  = {Invited Lecture}
}

@InProceedings{   criscione_zarathustra_2014,
  shorttitle    = {Zarathustra},
  author        = {Criscione, Claudio and Bosatelli, Fabio and Zanero, Stefano
                  and Maggi, Federico},
  title         = {Zarathustra: {{Extracting WebInject Signatures}} from
                  {{Banking Trojans}}},
  publisher     = {{IEEE Computer Society}},
  booktitle     = {Proceedings of the {{Twelfth Annual International
                  Conference}} on {{Privacy}}, {{Security}} and {{Trust}}
                  ({{PST}})},
  pages         = {139--148},
  location      = {{Toronto, Canada}},
  abstract      = {Modern trojans are equipped with a functionality, called
                  WebInject, that can be used to silently modify a web page on
                  the infected end host. Given its flexibility, WebInject-based
                  malware is becoming a popular information-stealing mechanism.
                  In addition, the structured and well-organized
                  malware-as-a-service model makes revenue out of customization
                  kits, which in turns leads to high volumes of binary
                  variants. Analysis approaches based on memory carving to
                  extract the decrypted webinject.txt and config.bin files at
                  runtime make the strong assumption that the malware will
                  never change the way such files are handled internally, and
                  therefore are not future proof by design. In addition,
                  developers of sensitive web applications (e.g., online
                  banking) have no tools that they can possibly use to even
                  mitigate the effect of WebInjects.},
  doi           = {10.1109/PST.2014.6890933},
  isbn          = {978-1-4799-3502-4},
  date          = {2014-07}
}

@InProceedings{   lindorfer_andradar_2014,
  shorttitle    = {AndRadar},
  author        = {Lindorfer, Martina and Volanis, Stamatis and Sisto,
                  Alessandro and Neugschwandtner, Matthias and Athanasopoulos,
                  Elias and Maggi, Federico and Platzer, Christian and Zanero,
                  Stefano and Ioannidis, Sotiris},
  title         = {{{AndRadar}}: {{Fast Discovery}} of {{Android Applications}}
                  in {{Alternative Markets}}},
  publisher     = {{Springer International Publishing}},
  editor        = {Dietrich, Sven},
  booktitle     = {Detection of {{Intrusions}} and {{Malware}}, and
                  {{Vulnerability Assessment}}},
  series        = {Lecture Notes in Computer Science},
  pages         = {51--71},
  abstract      = {Compared to traditional desktop software, Android
                  applications are delivered through software repositories,
                  commonly known as application markets. Other mobile
                  platforms, such as Apple iOS and BlackBerry OS also use the
                  marketplace model, but what is unique to Android is the
                  existence of a plethora of alternative application markets.
                  This complicates the task of detecting and tracking Android
                  malware. Identifying a malicious application in one
                  particular market is simply not enough, as many instances of
                  this application may exist in other markets. To quantify this
                  phenomenon, we exhaustively crawled 8 markets between June
                  and November 2013. Our findings indicate that alternative
                  markets host a large number of ad-aggressive apps, a
                  non-negligible amount of malware, and some markets even allow
                  authors to publish known malicious apps without prompt
                  action. Motivated by these findings, we present AndRadar, a
                  framework for discovering multiple instances of a malicious
                  Android application in a set of alternative application
                  markets. AndRadar scans a set of markets in parallel to
                  discover similar applications. Each lookup takes no more than
                  a few seconds, regardless of the size of the marketplace.
                  Moreover, it is modular, and new markets can be transparently
                  added once the search and download URLs are known. Using
                  AndRadar we are able to achieve three goals. First, we can
                  discover malicious applications in alternative markets,
                  second, we can expose app distribution strategies used by
                  malware developers, and third, we can monitor how different
                  markets react to new malware. During a three-month evaluation
                  period, AndRadar tracked over 20,000 apps and recorded more
                  than 1,500 app deletions in 16 markets. Nearly 8\% of those
                  deletions were related to apps that were hopping from market
                  to market. The most established markets were able to react
                  and delete new malware within tens of days from the malicious
                  app publication date while other markets did not react at
                  all.},
  doi           = {10.1007/978-3-319-08509-8_4},
  isbn          = {978-3-319-08508-1 978-3-319-08509-8},
  date          = {2014-07},
  url           = {http://link.springer.com/chapter/10.1007/978-3-319-08509-8_4}
}

@InProceedings{   schiavoni_phoenix_2014,
  shorttitle    = {Phoenix},
  author        = {Schiavoni, Stefano and Maggi, Federico and Cavallaro,
                  Lorenzo and Zanero, Stefano},
  title         = {Phoenix: {{DGA-Based Botnet Tracking}} and
                  {{Intelligence}}},
  publisher     = {{Springer International Publishing}},
  editor        = {Dietrich, Sven},
  booktitle     = {Proceedings of the {{International Conference}} on
                  {{Detection}} of {{Intrusions}} and {{Malware}}, and
                  {{Vulnerability Assessment}} ({{DIMVA}})},
  series        = {Lecture Notes in Computer Science},
  pages         = {192--211},
  abstract      = {Modern botnets rely on domain-generation algorithms (DGAs)
                  to build resilient command-and-control infrastructures. Given
                  the prevalence of this mechanism, recent work has focused on
                  the analysis of DNS traffic to recognize botnets based on
                  their DGAs. While previous work has concentrated on
                  detection, we focus on supporting intelligence operations. We
                  propose Phoenix, a mechanism that, in addition to telling
                  DGA- and non-DGA-generated domains apart using a combination
                  of string and IP-based features, characterizes the DGAs
                  behind them, and, most importantly, finds groups of
                  DGA-generated domains that are representative of the
                  respective botnets. As a result, Phoenix can associate
                  previously unknown DGA-generated domains to these groups, and
                  produce novel knowledge about the evolving behavior of each
                  tracked botnet. We evaluated Phoenix on 1,153,516 domains,
                  including DGA-generated domains from modern, well-known
                  botnets: without supervision, it correctly distinguished DGA-
                  vs. non-DGA-generated domains in 94.8 percent of the cases,
                  characterized families of domains that belonged to distinct
                  DGAs, and helped researchers ``on the field'' in gathering
                  intelligence on suspicious domains to identify the correct
                  botnet.},
  doi           = {10.1007/978-3-319-08509-8_11},
  isbn          = {978-3-319-08508-1 978-3-319-08509-8},
  date          = {2014-07},
  url           = {http://link.springer.com/chapter/10.1007/978-3-319-08509-8_11}
}

@InProceedings{   carminati_banksealer_2014,
  shorttitle    = {BankSealer},
  author        = {Carminati, Michele and Caron, Roberto and Maggi, Federico
                  and Epifani, Ilenia and Zanero, Stefano},
  title         = {{{BankSealer}}: {{An Online Banking Fraud Analysis}} and
                  {{Decision Support System}}},
  publisher     = {{Springer Berlin Heidelberg}},
  editor        = {Cuppens-Boulahia, Nora and Cuppens, Fr{\'e}d{\'e}ric and
                  Jajodia, Sushil and Kalam, Anas Abou El and Sans, Thierry},
  booktitle     = {{{ICT Systems Security}} and {{Privacy Protection}}},
  series        = {IFIP Advances in Information and Communication Technology},
  pages         = {380--394},
  abstract      = {We propose a semi-supervised online banking fraud analysis
                  and decision support approach. During a training phase, it
                  builds a profile for each customer based on past
                  transactions. At runtime, it supports the analyst by ranking
                  unforeseen transactions that deviate from the learned
                  profiles. It uses methods whose output has a immediate
                  statistical meaning that provide the analyst with an
                  easy-to-understand model of each customer's spending habits.
                  First, we quantify the anomaly of each transaction with
                  respect to the customer historical profile. Second, we find
                  global clusters of customers with similar spending habits.
                  Third, we use a temporal threshold system that measures the
                  anomaly of the current spending pattern of each customer,
                  with respect to his or her past spending behavior. As a
                  result, we mitigate the undertraining due to the lack of
                  historical data for building of well-trained profiles (of
                  fresh users), and the users that change their (spending)
                  habits over time. Our evaluation on real-world data shows
                  that our approach correctly ranks complex frauds as ``top
                  priority''.},
  doi           = {10.1007/978-3-642-55415-5_32},
  isbn          = {978-3-642-55414-8 978-3-642-55415-5},
  date          = {2014-06-02},
  url           = {http://link.springer.com/chapter/10.1007/978-3-642-55415-5_32}
}

@Unpublished{     maggi_phoenixhoneynet_talk_2014,
  shorttitle    = {PhoenixHoneynet},
  author        = {Maggi, Federico},
  title         = {Tracking and {{Characterizing Botnets Using Automatically
                  Generated Domains}}},
  eventtitle    = {{Honeynet Workshop}},
  abstract      = {Modern botnets rely on domain-generation algorithms (DGAs)
                  to build resilient command-and-control infrastructures.
                  Recent works focus on recognizing automatically generated
                  domains (AGDs) from DNS traffic, which potentially allows to
                  identify previously unknown AGDs to hinder or disrupt
                  botnets' communication capabilities. The state-of-the-art
                  approaches require to deploy low-level DNS sensors to access
                  data whose collection poses practical and privacy issues,
                  making their adoption problematic. We propose a mechanism
                  that overcomes the above limitations by analyzing DNS traffic
                  data through a combination of linguistic and IP-based
                  features of suspicious domains. In this way, we are able to
                  identify AGD names, characterize their DGAs and isolate
                  logical groups of domains that represent the respective
                  botnets. Moreover, our system enriches these groups with new,
                  previously unknown AGD names, and produce novel knowledge
                  about the evolving behavior of each tracked botnet. We used
                  our system in real-world settings, to help researchers that
                  requested intelligence on suspicious domains and were able to
                  label them as belonging to the correct botnet automatically.
                  Additionally, we ran an evaluation on 1,153,516 domains,
                  including AGDs from both modern (e.g., Bamital) and
                  traditional (e.g., Conficker, Torpig) botnets. Our approach
                  correctly isolated families of AGDs that belonged to distinct
                  DGAs, and set automatically generated from non-automatically
                  generated domains apart in 94.8 percent of the cases.},
  location      = {{Warsaw, Poland}},
  date          = {2014-05-14},
  howpublished  = {Invited Talk}
}

@Unpublished{     maggi_phoenixgoogle_talk_2014,
  shorttitle    = {PhoenixGoogle},
  author        = {Maggi, Federico},
  title         = {Phoenix \& {{Cerberus}}: {{Botnet}} Tracking via Precise
                  {{DGA}} Characterization},
  eventtitle    = {{Google Tech Talk}},
  location      = {{Google, Mountain View, CA, USA}},
  date          = {2014-05},
  howpublished  = {Invited Talk}
}

@InProceedings{   nikiforakis_strangerdanger_2014,
  shorttitle    = {StrangerDanger},
  author        = {Nikiforakis, Nick and Maggi, Federico and Stringhini,
                  Gianluca and Rafique, M. Zubair and Joosen, Wouter and
                  Kruegel, Christopher and Piessens, Frank and Vigna, Giovanni
                  and Zanero, Stefano},
  title         = {Stranger {{Danger}}: {{Exploring}} the {{Ecosystem}} of
                  {{Ad}}-based {{URL Shortening Services}}},
  publisher     = {{International World Wide Web Conferences Steering
                  Committee}},
  booktitle     = {Proceedings of the 23rd {{International Conference}} on
                  {{World Wide Web}}},
  series        = {WWW '14},
  pages         = {51--62},
  location      = {{Seoul, Korea}},
  abstract      = {URL shortening services facilitate the need of exchanging
                  long URLs using limited space, by creating compact URL
                  aliases that redirect users to the original URLs when
                  followed. Some of these services show advertisements (ads) to
                  link-clicking users and pay a commission of their advertising
                  earnings to link-shortening users. In this paper, we
                  investigate the ecosystem of these increasingly popular
                  ad-based URL shortening services. Even though traditional URL
                  shortening services have been thoroughly investigated in
                  previous research, we argue that, due to the monetary
                  incentives and the presence of third-party advertising
                  networks, ad-based URL shortening services and their users
                  are exposed to more hazards than traditional shortening
                  services. By analyzing the services themselves, the
                  advertisers involved, and their users, we uncover a series of
                  issues that are actively exploited by malicious advertisers
                  and endanger the users. Moreover, next to documenting the
                  ongoing abuse, we suggest a series of defense mechanisms that
                  services and users can adopt to protect themselves.},
  doi           = {10.1145/2566486.2567983},
  isbn          = {978-1-4503-2744-2},
  date          = {2014-04},
  url           = {http://dx.doi.org/10.1145/2566486.2567983}
}

@InProceedings{   spagnuolo_bitiodine_2014,
  shorttitle    = {BitIodine},
  author        = {Spagnuolo, Michele and Maggi, Federico and Zanero, Stefano},
  title         = {{{BitIodine}}: {{Extracting Intelligence}} from the
                  {{Bitcoin Network}}},
  publisher     = {{Springer Berlin Heidelberg}},
  booktitle     = {Financial {{Cryptography}} and {{Data Security}}},
  series        = {Lecture Notes in Computer Science (LNCS)},
  pages         = {457--468},
  location      = {{Barbados}},
  abstract      = {Bitcoin, the famous peer-to-peer, decentralized electronic
                  currency system, allows users to benefit from pseudonymity,
                  by generating an arbitrary number of aliases (or addresses)
                  to move funds. However, the complete history of all
                  transactions ever performed, called "blockchain", is public
                  and replicated on each node. The data it contains is
                  difficult to analyze manually, but can yield a high number of
                  relevant information.
                  
                  In this paper we present a modular framework, BitIodine,
                  which parses the blockchain, clusters addresses that are
                  likely to belong to a same user or group of users, classifies
                  such users and labels them, and finally visualizes complex
                  information extracted from the Bitcoin network.
                  
                  BitIodine labels users (semi-)automatically with information
                  on their identity and actions which is automatically scraped
                  from openly available information sources. BitIodine also
                  supports manual investigation by finding paths and reverse
                  paths between addresses or users.
                  
                  We tested BitIodine on several real-world use cases,
                  identified an address likely to belong to the encrypted Silk
                  Road cold wallet, or investigated the CryptoLocker ransomware
                  and accurately quantified the number of ransoms paid, as well
                  as information about the victims.
                  
                  We release an early prototype of BitIodine as a library for
                  building more complex Bitcoin forensic analysis tools.},
  doi           = {10.1007/978-3-662-45472-5_29},
  isbn          = {978-3-662-45471-8},
  date          = {2014-03-03}
}

@TechReport{      gianazza_puppetdroid_tr_2014,
  shorttitle    = {PuppetDroid},
  author        = {Gianazza, Andrea and Maggi, Federico and Fattori, Aristide
                  and Cavallaro, Lorenzo and Zanero, Stefano},
  title         = {{{PuppetDroid}}: {{A User-Centric UI Exerciser}} for
                  {{Automatic Dynamic Analysis}} of {{Similar Android
                  Applications}}},
  institution   = {{arXiv}},
  abstract      = {Popularity and complexity of malicious mobile applications
                  are rising, making their analysis difficult and labor
                  intensive. Mobile application analysis is indeed inherently
                  different from desktop application analysis: In the latter,
                  the interaction of the user (i.e., victim) is crucial for the
                  malware to correctly expose all its malicious behaviors. We
                  propose a novel approach to analyze (malicious) mobile
                  applications. The goal is to exercise the user interface (UI)
                  of an Android application to effectively trigger malicious
                  behaviors, automatically. Our key intuition is to record and
                  reproduce the UI interactions of a potential victim of the
                  malware, so as to stimulate the relevant behaviors during
                  dynamic analysis. To make our approach scale, we
                  automatically re-execute the recorded UI interactions on apps
                  that are similar to the original ones. These characteristics
                  make our system orthogonal and complementary to current
                  dynamic analysis and UI-exercising approaches. We developed
                  our approach and experimentally shown that our stimulation
                  allows to reach a higher code coverage than automatic UI
                  exercisers, so to unveil interesting malicious behaviors that
                  are not exposed when using other approaches. Our approach is
                  also suitable for crowdsourcing scenarios, which would push
                  further the collection of new stimulation traces. This can
                  potentially change the way we conduct dynamic analysis of
                  (mobile) applications, from fully automatic only, to
                  user-centric and collaborative too.},
  date          = {2014-02-19},
  url           = {http://arxiv.org/abs/1402.4826}
}

@Unpublished{     maggi_androidmalware_talk_2014,
  shorttitle    = {AndroidMalware},
  author        = {Maggi, Federico},
  title         = {Malicious {{Android Apps}}: {{Overview}}, {{Status}} and
                  {{Dilemmas}}},
  location      = {{Qualcomm, San Diego, USA}},
  date          = {2014-01-03},
  url           = {http://s.maggi.cc/android-malware-2013},
  howpublished  = {Invited Talk}
}

@InProceedings{   bonetti_ssdforensics_2013,
  shorttitle    = {SSDForensics},
  author        = {Bonetti, Gabriele and Viglione, Marco and Frossi, Alessandro
                  and Maggi, Federico and Zanero, Stefano},
  title         = {A {{Comprehensive Black}}-box {{Methodology}} for
                  {{Testing}} the {{Forensic Characteristics}} of
                  {{Solid}}-state {{Drives}}},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the 29th {{Annual Computer Security
                  Applications Conference}}},
  series        = {ACSAC '13},
  pages         = {269--278},
  location      = {{New York, NY, USA}},
  abstract      = {Solid-state drives (SSDs) are inherently different from
                  traditional drives, as they incorporate data-optimization
                  mechanisms to overcome their limitations (such as a limited
                  number of program-erase cycles, or the need of blanking a
                  block before writing). The most common optimizations are wear
                  leveling, trimming, compression, and garbage collection,
                  which operate transparently to the host OS and, in certain
                  cases, even when the disks are disconnected from a computer
                  (but still powered up). In simple words, SSD controllers are
                  designed to hide these internals completely, rendering them
                  inaccessible if not through direct acquisition of the memory
                  cells. These optimizations have a significant impact on the
                  forensic analysis of SSDs. The main cause is that memory
                  cells could be pre-emptively blanked, whereas a traditional
                  drive sector would need to be explicitly rewritten to
                  physically wipe off the data. Unfortunately, the existing
                  literature on this subject is sparse and the conclusions are
                  seemingly contradictory. In this paper we propose a generic,
                  practical, test-driven methodology that guides researchers
                  and forensics analysts through a series of steps that assess
                  the "forensic friendliness" of a SSD. Given a drive of the
                  same brand and model of the one under analysis, our
                  methodology produces a decision that helps an analyst to
                  determine whether or not an expensive direct acquisition of
                  the memory cells is worth the effort, because the extreme
                  optimizations may have rendered the data unreadable or
                  useless. We apply our methodology to three SSDs produced by
                  top vendors (Samsung, Corsair, and Crucial), and provide a
                  detailed description of how each step should be conducted.},
  doi           = {10.1145/2523649.2523660},
  isbn          = {978-1-4503-2015-3},
  date          = {2013-12},
  url           = {http://doi.acm.org/10.1145/2523649.2523660}
}

@TechReport{      schiavoni_phoenix_tr_2013,
  shorttitle    = {Phoenix},
  author        = {Schiavoni, Stefano and Maggi, Federico and Cavallaro,
                  Lorenzo and Zanero, Stefano},
  title         = {Tracking and {{Characterizing Botnets Using Automatically
                  Generated Domains}}},
  institution   = {{arXiv}},
  abstract      = {Modern botnets rely on domain-generation algorithms (DGAs)
                  to build resilient command-and-control infrastructures.
                  Recent works focus on recognizing automatically generated
                  domains (AGDs) from DNS traffic, which potentially allows to
                  identify previously unknown AGDs to hinder or disrupt
                  botnets' communication capabilities. The state-of-the-art
                  approaches require to deploy low-level DNS sensors to access
                  data whose collection poses practical and privacy issues,
                  making their adoption problematic. We propose a mechanism
                  that overcomes the above limitations by analyzing DNS traffic
                  data through a combination of linguistic and IP-based
                  features of suspicious domains. In this way, we are able to
                  identify AGD names, characterize their DGAs and isolate
                  logical groups of domains that represent the respective
                  botnets. Moreover, our system enriches these groups with new,
                  previously unknown AGD names, and produce novel knowledge
                  about the evolving behavior of each tracked botnet. We used
                  our system in real-world settings, to help researchers that
                  requested intelligence on suspicious domains and were able to
                  label them as belonging to the correct botnet automatically.
                  Additionally, we ran an evaluation on 1,153,516 domains,
                  including AGDs from both modern (e.g., Bamital) and
                  traditional (e.g., Conficker, Torpig) botnets. Our approach
                  correctly isolated families of AGDs that belonged to distinct
                  DGAs, and set automatically generated from non-automatically
                  generated domains apart in 94.8 percent of the cases.},
  date          = {2013-11-21},
  url           = {http://arxiv.org/abs/1311.5612}
}

@Unpublished{     maggi_phoenixinfosek_talk_2013,
  shorttitle    = {PhoenixInfosek},
  author        = {Maggi, Federico},
  title         = {Modern {{Botnets}} and the {{Rise}} of {{Automatically
                  Generated Domains}}},
  eventtitle    = {{InfoSek}},
  location      = {{Nova Gorica, Slovenia}},
  date          = {2013-11-20},
  howpublished  = {Invited Talk}
}

@Unpublished{     maggi_andrototalinfosek_talk_2013,
  shorttitle    = {AndroTotalInfosek},
  author        = {Maggi, Federico},
  title         = {{{AndroTotal}}: {{A Scalable Framework}} for {{Android
                  Antivirus Testing}}},
  eventtitle    = {{InfoSek}},
  location      = {{Nova Gorica, Slovenia}},
  date          = {2013-11-20},
  howpublished  = {Invited Talk}
}

@Unpublished{     maggi_andrototalsecure_talk_2013,
  shorttitle    = {AndroTotalSecure},
  author        = {Maggi, Federico},
  title         = {{{AndroTotal}}: {{A Scalable Framework}} for {{Android
                  Antimalware Testing}}},
  eventtitle    = {{Secure}},
  abstract      = {Although there are controversial opinions regarding how
                  large the mobile malware phenomenon is in terms of absolute
                  numbers, hype aside, the amount of new Android malware
                  variants is increasing. This trend is mainly due to the fact
                  that, as it happened with traditional malware, the authors
                  are striving to repackage, obfuscate, or otherwise transform
                  the executable code of their malicious apps in order to evade
                  mobile security apps. There are about 85 of these apps only
                  on the official marketplace. However, it is not clear how
                  effective they are. Indeed, the sandboxing mechanism of
                  Android does not allow (security) apps to audit other apps.
                  We present AndroTotal, a publicly available tool, malware
                  repository and research framework that aims at mitigating the
                  above challenges, and allow researchers to automatically scan
                  Android apps against an arbitrary set of malware detectors.
                  We implemented AndroTotal and released it to the research
                  community in April 2013. So far, we collected 18,758 distinct
                  submitted samples and received the attention of several
                  research groups (1,000 distinct accounts), who integrated
                  their malware-analysis services with ours.},
  location      = {{Warsaw, Poland}},
  date          = {2013-10-09},
  howpublished  = {Invited Talk}
}

@Article{         nacci_mpower_article_2013,
  shorttitle    = {MPower},
  author        = {Nacci, Alessandro and Trov{\`o}, Francesco and Maggi,
                  Federico and Ferroni, Matteo and Cazzola, Andrea and Sciuto,
                  Donatella and Santambrogio, Marco},
  title         = {Adaptive and {{Flexible Smartphone Power Modeling}}},
  journaltitle  = {Mobile Networks and Applications},
  pages         = {1--10},
  abstract      = {Mobile devices have become the main interaction mean between
                  users and the surrounding environment. An indirect measure of
                  this trend is the increasing amount of security threats
                  against mobile devices, which in turn created a demand for
                  protection tools. Protection tools, unfortunately, add an
                  additional burden for the smartphone's battery power, which
                  is a precious resource. This observation motivates the need
                  for smarter (security) applications, designed and capable of
                  running within adaptive energy goals. Although this problem
                  affects other areas, in the security area this research
                  direction is referred to as "green security". In general, a
                  fundamental need to the researches toward creating
                  energy-aware applications, consist in having appropriate
                  power models that capture the full dynamic of devices and
                  users. This is not an easy task because of the highly dynamic
                  environment and usage habits. In practice, this goal requires
                  easy mechanisms to measure the power consumption and
                  approaches to create accurate models. The existing approaches
                  that tackle this problem are either not accurate or not
                  applicable in practice due to their limiting requirements. We
                  propose MPower, a power-sensing platform and adaptive power
                  modeling platform for Android mobile devices. The MPower
                  approach creates an adequate and precise knowledge base of
                  the power "behavior" of several different devices and users,
                  which allows us to create better device-centric power models
                  that considers the main hardware components and how they
                  contributed to the overall power consumption. In this paper
                  we consolidate our perspective work on MPower by providing
                  the implementation details and evaluation on 278 users and
                  about 22.5 million power-related data. Also, we explain how
                  MPower is useful in those scenarios where low-power,
                  unobtrusive, accurate power modeling is necessary (e.g.,
                  green security applications).},
  doi           = {10.1007/s11036-013-0470-y},
  issn          = {1383-469X},
  date          = {2013-10-01}
}

@InProceedings{   maggi_andrototal_2013,
  shorttitle    = {AndroTotal},
  author        = {Maggi, Federico and Valdi, Andrea and Zanero, Stefano},
  title         = {{{AndroTotal}}: {{A Flexible}}, {{Scalable Toolbox}} and
                  {{Service}} for {{Testing Mobile Malware Detectors}}},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the {{Third ACM Workshop}} on {{Security}}
                  and {{Privacy}} in {{Smartphones}} \& {{Mobile Devices}}},
  series        = {SPSM '13},
  pages         = {49--54},
  location      = {{New York, NY, USA}},
  abstract      = {Although there are controversial opinions regarding how
                  large the mobile malware phenomenon is in terms of absolute
                  numbers, hype aside, the amount of new Android malware
                  variants is increasing. This trend is mainly due to the fact
                  that, as it happened with traditional malware, the authors
                  are striving to repackage, obfuscate, or otherwise transform
                  the executable code of their malicious apps in order to evade
                  mobile security apps. There are about 85 of these apps only
                  on the official marketplace. However, it is not clear how
                  effective they are. Indeed, the sandboxing mechanism of
                  Android does not allow (security) apps to audit other apps.
                  We present AndroTotal, a publicly available tool, malware
                  repository and research framework that aims at mitigating the
                  above challenges, and allow researchers to automatically scan
                  Android apps against an arbitrary set of malware detectors.
                  We implemented AndroTotal and released it to the research
                  community in April 2013. So far, we collected 18,758 distinct
                  submitted samples and received the attention of several
                  research groups (1,000 distinct accounts), who integrated
                  their malware-analysis services with ours.},
  doi           = {10.1145/2516760.2516768},
  isbn          = {978-1-4503-2491-5},
  date          = {2013-10},
  url           = {http://doi.acm.org/10.1145/2516760.2516768},
  keywords      = {workshop}
}

@Article{         dardanelli_cartox_article_2013,
  shorttitle    = {CarToX},
  author        = {Dardanelli, Andrea and Maggi, Federico and Tanelli, Mara and
                  Zanero, Stefano and Savaresi, Sergio M and Kochanek, Roman
                  and Holz, Thorsten},
  title         = {A {{Security Layer}} for {{Smartphone}}-to-{{Vehicle
                  Communication}} over {{Bluetooth}}},
  journaltitle  = {Embedded Systems Letters},
  volume        = {5},
  number        = {3},
  pages         = {34--37},
  abstract      = {Modern vehicles are increasingly being interconnected with
                  computer systems, which collect information both from
                  vehicular sources and Internet services. Unfortunately, this
                  creates a non negligible attack surface, which extends when
                  vehicles are partly operated via smartphones. In this letter,
                  a hierarchically distributed control system architecture
                  which integrates a smartphone with classical embedded systems
                  is presented, and an ad-hoc, end-to-end security layer is
                  designed to demonstrate how a smartphone can interact
                  securely with a modern vehicle without requiring
                  modifications to the existing in-vehicle network.
                  Experimental results demonstrate the effectiveness of the
                  approach.},
  doi           = {10.1109/LES.2013.2264594},
  issn          = {1943-0663},
  date          = {2013-06-21}
}

@InProceedings{   maggi_longshore_2013,
  shorttitle    = {LongShore},
  author        = {Maggi, Federico and Frossi, Alessandro and Zanero, Stefano
                  and Stringhini, Gianluca and Stone-Gross, Brett and Kruegel,
                  Christopher and Vigna, Giovanni},
  title         = {Two years of short {{URLs}} internet measurement: security
                  threats and countermeasures},
  publisher     = {{International World Wide Web Conferences Steering
                  Committee}},
  booktitle     = {Proceedings of the 22nd international conference on {{World
                  Wide Web}} ({{WWW}})},
  pages         = {861--872},
  location      = {{Republic and Canton of Geneva, Switzerland}},
  abstract      = {URL shortening services have become extremely popular.
                  However, it is still unclear whether they are an effective
                  and reliable tool that can be leveraged to hide malicious
                  URLs, and to what extent these abuses can impact the end
                  users. With these questions in mind, we first analyzed
                  existing countermeasures adopted by popular shortening
                  services. Surprisingly, we found such countermeasures to be
                  ineffective and trivial to bypass. This first measurement
                  motivated us to proceed further with a large-scale collection
                  of the HTTP interactions that originate when web users access
                  live pages that contain short URLs. To this end, we monitored
                  622 distinct URL shortening services between March 2010 and
                  April 2012, and collected 24,953,881 distinct short URLs.
                  With this large dataset, we studied the abuse of short URLs.
                  Despite short URLs are a significant, new security risk, in
                  accordance with the reports resulting from the observation of
                  the overall phishing and spamming activity, we found that
                  only a relatively small fraction of users ever encountered
                  malicious short URLs. Interestingly, during the second year
                  of measurement, we noticed an increased percentage of short
                  URLs being abused for drive-by download campaigns and a
                  decreased percentage of short URLs being abused for spam
                  campaigns. In addition to these security-related findings,
                  our unique monitoring infrastructure and large dataset
                  allowed us to complement previous research on short URLs and
                  analyze these web services from the user's perspective.},
  isbn          = {978-1-4503-2035-1},
  date          = {2013-05}
}

@Unpublished{     maggi_andrototalmit_talk_2013,
  shorttitle    = {AndroTotalMIT},
  author        = {Maggi, Federico},
  title         = {{{AndroTotal}}: {{A Scalable Framework}} for {{Android
                  Antimalware Testing}}},
  eventtitle    = {{MIT CSAIL-POLIMI Workshop}},
  abstract      = {Although there are controversial opinions regarding how
                  large the mobile malware phenomenon is in terms of absolute
                  numbers, hype aside, the amount of new Android malware
                  variants is increasing. This trend is mainly due to the fact
                  that, as it happened with traditional malware, the authors
                  are striving to repackage, obfuscate, or otherwise transform
                  the executable code of their malicious apps in order to evade
                  mobile security apps. There are about 85 of these apps only
                  on the official marketplace. However, it is not clear how
                  effective they are. Indeed, the sandboxing mechanism of
                  Android does not allow (security) apps to audit other apps.
                  We present AndroTotal, a publicly available tool, malware
                  repository and research framework that aims at mitigating the
                  above challenges, and allow researchers to automatically scan
                  Android apps against an arbitrary set of malware detectors.
                  We implemented AndroTotal and released it to the research
                  community in April 2013. So far, we collected 18,758 distinct
                  submitted samples and received the attention of several
                  research groups (1,000 distinct accounts), who integrated
                  their malware-analysis services with ours.},
  location      = {{MIT, Boston, Massachussets, USA}},
  date          = {2013-05},
  howpublished  = {Invited Talk}
}

@Unpublished{     maggi_soauth_talk_2013,
  shorttitle    = {SoAuth},
  author        = {Maggi, Federico},
  title         = {Our {{Face}} are {{Belong}} to us: {{Breaking Facebook}}'s
                  {{Social Authentication}}},
  eventtitle    = {{Hek.si}},
  abstract      = {Two-factor authentication is widely used by high-value
                  services to prevent adversaries from compromising accounts
                  using stolen credentials. Facebook has recently released a
                  two-factor authentication mechanism, referred to as Social
                  Authentication, which requires users to identify some of
                  their friends in randomly selected photos. A recent study has
                  provided a formal analysis of social authentication
                  weaknesses against attackers inside the victim's social
                  circles. In this paper, we extend the threat model and study
                  the attack surface of social authentication in practice, and
                  show how any attacker can obtain the information needed to
                  solve the challenges presented by Facebook. We implement a
                  proof-of-concept system that utilizes widely available face
                  recognition software and cloud services, and evaluate it
                  using real public data collected from Facebook. Under the
                  assumptions of Facebook's threat model, our results show that
                  an attacker can obtain access to (sensitive) information for
                  at least 42\% of a user's friends that Facebook uses to
                  generate social authentication challenges. By relying solely
                  on publicly accessible information, a casual attacker can
                  solve 22\% of the social authentication tests in an automated
                  fashion, and gain a significant advantage for an additional
                  56\% of the tests, as opposed to just guessing. Additionally,
                  we simulate the scenario of a determined attacker placing
                  himself inside the victim's social circle by employing dummy
                  accounts. In this case, the accuracy of our attack greatly
                  increases and reaches 100\% when 120 faces per friend are
                  accessible by the attacker, even though it is very accurate
                  with as little as 10 faces.},
  location      = {{Ljubljana, Slovenia}},
  date          = {2013-04},
  howpublished  = {Invited Talk}
}

@InProceedings{   lindorfer_beagle_2012,
  shorttitle    = {Beagle},
  author        = {Lindorfer, Martina and Federico, Alessandro Di and Maggi,
                  Federico and Comparetti, Paolo Milani and Zanero, Stefano},
  title         = {Lines of {{Malicious Code}}: {{Insights Into}} the
                  {{Malicious Software Industry}}},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the {{Annual Computer Security Applications
                  Conference}} ({{ACSAC}})},
  pages         = {349--358},
  location      = {{New York, NY, USA}},
  abstract      = {Malicious software installed on infected computers is a
                  fundamental component of online crime. Malware development
                  thus plays an essential role in the underground economy of
                  cyber-crime. Malware authors regularly update their software
                  to defeat defenses or to support new or improved criminal
                  business models. A large body of research has focused on
                  detecting malware, defending against it and identifying its
                  functionality. In addition to these goals, however, the
                  analysis of malware can provide a glimpse into the software
                  development industry that develops malicious code. In this
                  work, we present techniques to observe the evolution of a
                  malware family over time. First, we develop techniques to
                  compare versions of malicious code and quantify their
                  differences. Furthermore, we use behavior observed from
                  dynamic analysis to assign semantics to binary code and to
                  identify functional components within a malware binary. By
                  combining these techniques, we are able to monitor the
                  evolution of a malware's functional components. We implement
                  these techniques in a system we call BEAGLE, and apply it to
                  the observation of 16 malware strains over several months.
                  The results of these experiments provide insight into the
                  effort involved in updating malware code, and show that
                  BEAGLE can identify changes to individual malware
                  components.},
  doi           = {10.1145/2420950.2421001},
  isbn          = {978-1-4503-1312-4},
  date          = {2012-12-03}
}

@InProceedings{   polakis_soauth_2012,
  shorttitle    = {SoAuth},
  author        = {Polakis, Jason and Lancini, Marco and Kontaxis, Georgios and
                  Maggi, Federico and Ioannidis, Sotiris and Keromytis, Angelos
                  and Zanero, Stefano},
  title         = {All {{Your Face Are Belong}} to {{Us}}: {{Breaking
                  Facebook}}'s {{Social Authentication}}},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the {{Annual Computer Security Applications
                  Conference}} ({{ACSAC}})},
  pages         = {399--408},
  location      = {{New York, NY, USA}},
  abstract      = {Two-factor authentication is widely used by high-value
                  services to prevent adversaries from compromising accounts
                  using stolen credentials. Facebook has recently released a
                  two-factor authentication mechanism, referred to as Social
                  Authentication, which requires users to identify some of
                  their friends in randomly selected photos. A recent study has
                  provided a formal analysis of social authentication
                  weaknesses against attackers inside the victim's social
                  circles. In this paper, we extend the threat model and study
                  the attack surface of social authentication in practice, and
                  show how any attacker can obtain the information needed to
                  solve the challenges presented by Facebook. We implement a
                  proof-of-concept system that utilizes widely available face
                  recognition software and cloud services, and evaluate it
                  using real public data collected from Facebook. Under the
                  assumptions of Facebook's threat model, our results show that
                  an attacker can obtain access to (sensitive) information for
                  at least 42\% of a user's friends that Facebook uses to
                  generate social authentication challenges. By relying solely
                  on publicly accessible information, a casual attacker can
                  solve 22\% of the social authentication tests in an automated
                  fashion, and gain a significant advantage for an additional
                  56\% of the tests, as opposed to just guessing. Additionally,
                  we simulate the scenario of a determined attacker placing
                  himself inside the victim's social circle by employing dummy
                  accounts. In this case, the accuracy of our attack greatly
                  increases and reaches 100\% when 120 faces per friend are
                  accessible by the attacker, even though it is very accurate
                  with as little as 10 faces.},
  doi           = {10.1145/2420950.2421008},
  isbn          = {978-1-4503-1312-4},
  date          = {2012-12-03}
}

@TechReport{      kochanek_cartox_tr_2012,
  shorttitle    = {CarToX},
  author        = {Kochanek, Roman and Dardanelli, Andrea and Maggi, Federico
                  and Zanero, Stefano and Tanelli, Mara and Savaresi, Sergio
                  and Holz, Thorsten},
  title         = {Secure {{Integration}} of {{Mobile Devices}} for
                  {{Automotive Services}}},
  institution   = {{Politecnico di Milano}},
  number        = {2012-09},
  abstract      = {Modern vehicles, and in particular electric vehicles, are
                  increasingly being equipped with interconnected computer
                  systems, which collect information through vehicular sources
                  and remote, Internet-connected services. Unfortunately, this
                  creates a non-negligible attack surface, which extends even
                  more when vehicles are integrated with smartphones to offer
                  advanced services. In fact, embedded systems on vehicles have
                  been developed to address safety, not security requirements.
                  Furthermore, vehicles have real-time constraints, and the
                  typical embedded architectures used on board significantly
                  complicate security designs. In this paper, we introduce a
                  communication framework that addresses these challenges and
                  we demonstrate how a smartphone can interact with a vehicle
                  in a secure and safe manner. To this end, we design a
                  security session layer that ensures end-to-end security
                  transparently. We conduct an experimental evaluation on a
                  real implementation of our security layer, which shows that
                  our solution is practical and easy to use, satisfies
                  performance constraints, and meets real-time requirements by
                  taking into account the limited capabilities of our target
                  architecture. More precisely, we implement our approach for
                  an electrically-powered two-wheeler manufactured by Piaggio,
                  and show how a smartphone can interact via a wireless link
                  with the battery-life controller in a secure manner.
                  Interestingly, our approach is not limited to vehicles, but
                  can be used in other application domains where a smartphone
                  needs to securely interact with an embedded device.},
  date          = {2012-06-01}
}

@Unpublished{     maggi_longshore_talk_2012,
  shorttitle    = {LongShore},
  author        = {Maggi, Federico},
  title         = {The {{Long Story}} of {{Short URLs}}},
  eventtitle    = {{ISG Research Seminars}},
  abstract      = {I gave a talk based on these slides for the first time at
                  Royal Holloway University of London, in April 2012. This talk
                  discusses the results of a research that we have conducted
                  about the impact on users of short URLs. I describe a system
                  that we designed, implemented, and deployed that observes and
                  collects the short URLs that more than 7,000 real web users
                  have encountered while browsing the Web between March 2010
                  and April 2011 (and counting). On this dataset, which
                  comprises 16,075,693 distinct short URLs, we first precisely
                  characterized the usage habits observed during our collection
                  process, and the content typically referred by short URLs:
                  Users exhibit different usage habits depending on the type of
                  content they are using short URLs for. We then analyzed the
                  abuse of short URLs to hide the true URL of malicious pages:
                  This practice is not widespread, although we noticed that the
                  miscreants tend to post the same malicious short URL on
                  multiple pages. Finally, we analyzed the countermeasures of
                  shortening services against abuses of short URLs, and found
                  that they are trivially bypassed by shortening a benign URL
                  that turns malicious only a few moments after submitting it
                  to the shortening service.},
  location      = {{Royal Holloway University of London}},
  date          = {2012-05-01},
  howpublished  = {Invited Talk}
}

@InProceedings{   maggi_phdthesispaper_2012,
  shorttitle    = {PhDThesisPaper},
  author        = {Maggi, Federico and Zanero, Stefano},
  title         = {Integrated {{Detection}} of {{Anomalous Behavior}} of
                  {{Computer Infrastructures}}},
  publisher     = {{IEEE}},
  booktitle     = {Proceedings of the {{IEEE}}/{{IFIP Network Operations}} and
                  {{Management Symposium}} ({{NOMS}})},
  pages         = {866--871},
  abstract      = {Our research concentrates on anomaly detection techniques,
                  which have both industrial applications such as network
                  monitoring and protection, as well as research applications
                  such as software behavioral analysis or malware
                  classification. During our doctoral research, we worked on
                  anomaly detection from three different perspective, as a
                  complex computer infrastructure has several weak spots that
                  must be protected. We first focused on the operating system,
                  central to any computer, to avoid malicious code to subvert
                  its normal activity. Secondly, we concentrated on web
                  applications, which are the main interface to modern
                  computing: Because of their immense popularity, they have
                  indeed become the most targeted entry point of intrusions.
                  Last, we developed novel techniques with the aim of
                  identifying related events (e.g., alerts reported by
                  intrusion detection systems) to build new and more compact
                  knowledge to detect malicious activity on large-scale
                  systems. During our research we enhanced existing anomaly
                  detection tools and also contributed with new ones. Such
                  tools have been tested over different datasets, both
                  synthetic data and real network traffic, and lead to
                  interesting results that were accepted for publication at
                  main security venues.},
  doi           = {10.1109/NOMS.2012.6212001},
  isbn          = {978-1-4673-0269-2},
  date          = {2012-04-16}
}

@InProceedings{   maggi_avlabelling_2011,
  shorttitle    = {AVLabelling},
  author        = {Maggi, Federico and Bellini, Andrea and Salvaneschi, Guido
                  and Zanero, Stefano},
  title         = {Finding {{Non}}-trivial {{Malware Naming Inconsistencies}}},
  publisher     = {{Springer-Verlag}},
  booktitle     = {Proceedings of the 7th {{International Conference}} on
                  {{Information Systems Security}} ({{ICISS}})},
  volume        = {7093},
  series        = {Lecture Notes in Computer Science},
  pages         = {144--159},
  abstract      = {Malware analysts, and in particular antivirus vendors, never
                  agreed on a single naming convention for malware specimens.
                  This leads to confusion and difficulty more for researchers
                  than for practitioners for example, when comparing coverage
                  of different antivirus engines, when integrating and
                  systematizing known threats, or comparing the classifications
                  given by different detectors. Clearly, solving naming
                  inconsistencies is a very difficult task, as it requires that
                  vendors agree on a unified naming convention. More
                  importantly, solving inconsistencies is impossible without
                  knowing exactly where they are. Therefore, in this paper we
                  take a step back and concentrate on the problem of finding
                  inconsistencies. To this end, we first represent each
                  vendor's naming convention with a graph-based model. Second,
                  we give a precise definition of inconsistency with respect to
                  these models. Third, we define two quantitative measures to
                  calculate the overall degree of inconsistency between
                  vendors. In addition, we propose a fast algorithm that finds
                  non-trivial (i.e., beyond syntactic differences)
                  inconsistencies. Our experiments on four major antivirus
                  vendors and 98,798 real-world malware samples confirm
                  anecdotal observations that different vendors name viruses
                  differently. More importantly, we were able to find
                  inconsistencies that cannot be inferred at all by looking
                  solely at the syntax.},
  doi           = {10.1007/978-3-642-25560-1_10},
  date          = {2011-12-15}
}

@InProceedings{   maggi_iclearshot_2011,
  shorttitle    = {iClearshot},
  author        = {Maggi, Federico and Volpatto, Alberto and Gasparini, Simone
                  and Boracchi, Giacomo and Zanero, Stefano},
  title         = {A {{Fast Eavesdropping Attack Against Touchscreens}}},
  booktitle     = {Proceedings of the 7th {{International Conference}} on
                  {{Information Assurance}} and {{Security}} ({{IAS}})},
  pages         = {320--325},
  abstract      = {The pervasiveness of mobile devices increases the risk of
                  exposing sensitive information on the go. In this paper, we
                  arise this concern by presenting an automatic attack against
                  modern touchscreen keyboards. We demonstrate the attack
                  against the Apple iPhone 2010's most popular touchscreen
                  device although it can be adapted to other devices (e.g.,
                  Android) that employ similar key-magnifying keyboards. Our
                  attack processes the stream of frames from a video camera
                  (e.g., surveillance or portable camera) and recognizes
                  keystrokes online, in a fraction of the time needed to
                  perform the same task by direct observation or offline
                  analysis of a recorded video, which can be unfeasible for
                  large amount of data. Our attack detects, tracks, and
                  rectifies the target touchscreen, thus following the device
                  or camera's movements and eliminating possible perspective
                  distortions and rotations In real-world settings, our attack
                  can automatically recognize up to 97.07 percent of the
                  keystrokes (91.03 on average), with 1.15 percent of errors
                  (3.16 on average) at a speed ranging from 37 to 51 keystrokes
                  per minute.},
  doi           = {10.1109/ISIAS.2011.6122840},
  isbn          = {978-1-4577-2154-0},
  date          = {2011-12-05}
}

@Unpublished{     maggi_isnoop_talk_2011,
  shorttitle    = {iSnoop},
  author        = {Maggi, Federico and Volpatto, Alberto and Zanero, Stefano},
  title         = {{iSnoop}: How to Steal Secrets From Touchscreen Devices},
  eventtitle    = {{Black Hat Briefings Abu Dhabi}},
  abstract      = {Spying on a person is an easy and effective method to obtain
                  sensitive informations, even when the victim is well
                  protected against common digital attacks. Modern mobile
                  devices allow people to perform some information sensitive
                  actions in unsafe places, where anyone could easily observe
                  the victim while typing. What if your mobile phone has a cool
                  touchscreen interface that gives you graphical feedback as
                  you type (iPhone, Android, BlackBerry Torch)? Does it make
                  shoulder surfing easier or, worse, automatable?
                  
                  We believe so, and to demonstrate it, we developed a
                  practical shoulder surfing attack that automatically
                  reconstructs the sequence of keystrokes by aiming a camera at
                  the target touchscreen while the victim is typing. Our attack
                  exploits feedback such as magnified keys, often appearing in
                  predictable positions. This feedback mechanism has been
                  adopted by the top three touchscreen vendors (Apple iOS,
                  Google Android, RIM BlackBerry); in newer version of these
                  mobile OSs, the user has no way to disable it. To demonstrate
                  the effectiveness of our approach, we implemented it against
                  the iPhone (the most popular one), but it can be easily
                  adapted to similar devices with minor modifications.
                  
                  Our attack takes into account that, in real-world scenarios,
                  both the victim's device and attacker's spying camera are not
                  standing in fixed positions. To compensate their movements
                  and misalignments, our system detects and rectifies the
                  target screen before identifying keystokes. By doing that, we
                  are able to automatically recognize up to 97.07\% of the
                  keystrokes, with as low as 1.15\% errors and an average
                  processing speed that makes it a fast and quasi-real-time
                  alternative to shoulder surfing.},
  location      = {Abu Dhabi},
  date          = {2011-12},
  url           = {https://www.blackhat.com/html/bh-ad-11/bh-ad-11-archives.html},
  howpublished  = {Peer-reviewed Talk}
}

@InProceedings{   maggi_iclearshotposter_2011,
  shorttitle    = {iClearshotPoster},
  author        = {Maggi, Federico and Volpatto, Alberto and Gasparini, Simone
                  and Boracchi, Giacomo and Zanero, Stefano},
  title         = {{{POSTER}}: {{Fast}}, {{Automatic iPhone Shoulder
                  Surfing}}},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the 18th {{Conference}} on {{Computer}} and
                  {{Communication Security}} ({{CCS}})},
  abstract      = {Touchscreen devices increase the risk of shoulder surfing to
                  such an extent that attackers could steal sensitive
                  information by simply following the victim and observe his or
                  her portable device. We underline this concern by proposing
                  an automatic shoulder surfing attack against modern
                  touchscreen keyboards that display magnified keys in
                  predictable positions. We demonstrate this attack against the
                  Apple iPhone although it can work with other layouts and
                  different devices and show that it recognizes up to 97.07\%
                  (91.03\% on average) of the keystrokes, with only 1.15\% of
                  errors, at 37 to 51 keystrokes per minute: About eight times
                  faster than a human analyzing a recorded video. Our attack
                  accurately recovers the sequence of keystrokes input by the
                  user. A previous attack, which targeted desktop scenarios and
                  thus worked with very restrictive settings, is similar in
                  spirit to ours. However, as it assumes that camera and target
                  keyboard are both in fixed, perpendicular position, it cannot
                  suite mobile settings, characterized by moving target and
                  skewed, rotated viewpoints. Our attack, instead, requires no
                  particular settings and even allows for natural movements of
                  both target device and shoulder surfer's camera. In addition,
                  our attack yields accurate output without any grammar or
                  syntax checks, so that it can detect large context-free text
                  or non-dictionary words.},
  doi           = {10.1145/2093476.2093498},
  date          = {2011-10-01}
}

@InProceedings{   maggi_syssecpolimi_2011,
  shorttitle    = {SysSecPOLIMI},
  author        = {Maggi, Federico and Zanero, Stefano},
  title         = {System {{Security}} research at {{Politecnico}} di
                  {{Milano}}},
  publisher     = {{IEEE Computer Society}},
  booktitle     = {Proceedings of the 1st {{SysSec Workshop}} ({{SysSec}})},
  abstract      = {This paper summarizes the past, present and future lines of
                  research in the systems security area pursued by the
                  Performance Evaluation Lab of Politecnico di Milano. We
                  describe our past research in the area of learning algorithms
                  applied to intrusion detection, our current work in the area
                  of malware analysis, and our future research outlook,
                  oriented to the cloud, to mobile device security, and to
                  cyber-physical systems.},
  doi           = {10.1109/SysSec.2011.30},
  date          = {2011-07-06},
  keywords      = {workshop}
}

@InProceedings{   roveta_burn_2011,
  shorttitle    = {BURN},
  author        = {Roveta, Francesco and Di Mario, Luca and Maggi, Federico and
                  Caviglia, Giorgio and Zanero, Stefano and Ciuccarelli,
                  Paolo},
  title         = {{{BURN}}: {{Baring Unknown Rogue Networks}}},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the 8th {{International Symposium}} on
                  {{Visualization}} for {{Cyber Security}} ({{VizSec}})},
  pages         = {6:1--6:10},
  location      = {{New York, NY, USA}},
  abstract      = {Manual analysis of security-related events is still a
                  necessity to investigate non-trivial cyber attacks. This task
                  is particularly hard when the events involve slow, stealthy
                  and large-scale activities typical of the modern
                  cybercriminals' strategy. In this regard, visualization tools
                  can effectively help analysts in their investigations. In
                  this paper, we present BURN, an interactive visualization
                  tool for displaying autonomous systems exhibiting rogue
                  activity that helps at finding misbehaving networks through
                  visual and interactive exploration. Up to seven values are
                  displayed in a single visual element, while avoiding
                  cumbersome and confusing maps. To this end, animations and
                  alpha channels are leveraged to create simple views that
                  highlight relevant activity patterns. In addition, BURN
                  incorporates a simple algorithm to identify migrations of
                  nefarious services across autonomous systems, which can
                  support, for instance, root-cause analysis and law
                  enforcement investigations.},
  doi           = {10.1145/2016904.2016910},
  isbn          = {978-1-4503-0679-9},
  date          = {2011-06-20}
}

@InProceedings{   maggi_cloudids_2011,
  shorttitle    = {CloudIDS},
  author        = {Maggi, Federico and Zanero, Stefano},
  title         = {Is the future {{Web}} more insecure? {{Distractions}} and
                  solutions of new-old security issues and measures},
  publisher     = {{EWI}},
  booktitle     = {Proceedings of the {{Worldwide Cybersecurity Summit}}},
  pages         = {1--9},
  abstract      = {The world of information and communication technology is
                  experiencing changes that, regardless of some skepticism, are
                  bringing to life the concept of ``utility computing''. The
                  nostalgics observed a parallel between the emerging paradigm
                  of cloud computing and the traditional time-sharing era,
                  depicting clouds as the modern reincarnation of mainframes
                  available on a pay-per-use basis, and equipped with virtual,
                  elastic, disks-as-a-service that replace the old physical
                  disks with quotas. This comparison is fascinating, but more
                  importantly, in our opinion, it prepares the ground for
                  constructive critiques regarding the security of such a
                  computing paradigm and, especially, one of its key
                  components: web services. In this paper we discuss our
                  position about the current countermeasures (e.g., intrusion
                  detection systems, anti-malware), developed to mitigate
                  well-known web security threats. By reasoning on said
                  affinities, we focus on the simple case study of
                  anomaly-based approaches, which are employed in many modern
                  protection tools, not just in intrusion detectors. We
                  illustrate our position by the means of a simple running
                  example and show that attacks against injection
                  vulnerabilities, a widespread menace that is easily
                  recognizable with ordinary anomaly-based checks, can be
                  difficult to detect if web services are protected as they
                  were regular web applications. Along this line, we
                  concentrate on a few, critical hypotheses that demand
                  particular attention. Although in this emerging landscape
                  only a minority of threats qualify as novel, they could be
                  difficult to recognize with the current countermeasures and
                  thus can expose web services to new attacks. We conclude by
                  proposing simple modifications to the current countermeasures
                  to cope with the aforesaid security issues.},
  isbn          = {978-1-4577-1449-8},
  date          = {2011-06-01}
}

@InProceedings{   maggi_phonephishinghoneypot_2011,
  shorttitle    = {PhonePhishingHoneypot},
  author        = {Maggi, Federico and Sisto, Alessandro and Zanero, Stefano},
  title         = {A social-engineering-centric data collection initiative to
                  study phishing},
  publisher     = {{ACM}},
  booktitle     = {Proceedings of the {{First Workshop}} on {{Building Analysis
                  Datasets}} and {{Gathering Experience Returns}} for
                  {{Security}} ({{BADGERS}})},
  pages         = {107--108},
  location      = {{New York, NY, USA}},
  abstract      = {Phishers nowadays rely on a variety of channels, ranging
                  from old-fashioned emails to instant messages, social
                  networks, and the phone system (with both calls and text
                  messages), with the goal of reaching more victims. As a
                  consequence, modern phishing became a multi-faceted, even
                  more pervasive threat that is inherently more difficult to
                  study than traditional, email-based phishing. This short
                  paper describes the status of a data collection system we are
                  developing to capture different aspects of phishing
                  campaigns, with a particular focus on the emerging use of the
                  voice channel. The general approach is to record inbound
                  calls received on decoy phone lines, place outbound calls to
                  the same caller identifiers (when available) and also to
                  telephone numbers obtained from different sources.
                  Specifically, our system analyzes instant messages (e.g.,
                  automated social engineering attempts) and suspicious emails
                  (e.g., spam, phishing), and extracts telephone numbers, URLs
                  and popular words from the content. In addition, users can
                  voluntarily submit voice phishing (vishing) attempts through
                  a public website. Extracted telephone numbers, URLs and
                  popular words will be correlated to recognize campaigns by
                  means of cross-channel relationships between messages.},
  doi           = {10.1145/1978672.1978687},
  isbn          = {978-1-4503-0768-0},
  date          = {2011-04-10},
  keywords      = {workshop}
}

@InProceedings{   volpatto_cooperativeids_2010,
  shorttitle    = {CooperativeIDS},
  author        = {Volpatto, Alberto and Maggi, Federico and Zanero, Stefano},
  title         = {Effective {{Multimodel Anomaly Detection Using Cooperative
                  Negotiation}}},
  publisher     = {{Springer Berlin/Heidelberg}},
  booktitle     = {Proceedings of the {{Decision}} and {{Game Theory}} for
                  {{Security}} ({{GameSec}})},
  volume        = {6442},
  series        = {Lecture Notes in Computer Science},
  pages         = {180--191},
  doi           = {10.1007/978-3-642-17197-0_12},
  isbn          = {978-3-642-17196-3},
  date          = {2010-11-22}
}

@TechReport{      maggi_cloudids_tr_2010,
  shorttitle    = {CloudIDS},
  author        = {Maggi, Federico and Zanero, Stefano},
  title         = {Rethinking security in a cloudy world},
  institution   = {{Politecnico di Milano}},
  number        = {2010-11},
  abstract      = {The world of information and communication technology is
                  experiencing changes that, regardless of some skepticism, are
                  bringing to life the concept of ``utility computing''. The
                  nostalgics observed a parallel between the emerging paradigm
                  of cloud computing and the traditional time-sharing era,
                  depicting clouds as the modern reincarnation of mainframes
                  available on a pay-per-use basis, and equipped with virtual,
                  elastic, paid disks-as-a-service that replace the old
                  physical disks with quotas. This comparison is fascinating,
                  but more importantly, in our opinion, it prepares the ground
                  for constructive critiques regarding the security of such
                  computing paradigm. In this paper we explore similar
                  analogies to discuss our position about the current
                  countermeasures (e.g., intrusion detection systems,
                  anti-viruses), developed to mitigate well-known security
                  threats. By reasoning on said affinities, we focus on the
                  simple case of anomaly-based approaches, which are employed
                  in many modern protection tools, not just in intrusion
                  detectors. We illustrate our position by the means of a
                  simple running example and show that attacks against
                  injection vulnerabilities, a current menace that is easily
                  recognizable with ordinary anomaly-based checks, can be
                  difficult to detect if web services are assumed to be regular
                  web applications. Along this line, we concentrate on a few,
                  critical hypotheses that demand particular attention. We
                  conclude that, although only a minority of threats qualify as
                  novel, they are well camouflaged and can be difficult to
                  recognize behind the confusion caused by the cloud computing
                  excitement.},
  date          = {2010-11-11}
}

@TechReport{      maggi_iclearshot_tr_2010,
  shorttitle    = {iClearshot},
  author        = {Maggi, Federico and Volpatto, Alberto and Gasparini, Simone
                  and Boracchi, Giacomo and Zanero, Stefano},
  title         = {Don't touch a word! {{A}} practical input eavesdropping
                  attack against mobile touchscreen devices},
  institution   = {{Politecnico di Milano}},
  number        = {2010-59},
  abstract      = {Spying on a person is a subtle, yet easy and reliable method
                  to obtain sensitive information. Even if the victim is well
                  protected from digital attacks, spying may be a viable
                  option. In addition, the pervasiveness of mobile devices
                  increases an attacker's opportunities to observe the victims
                  while they are accessing or entering sensitive information.
                  This risk is exacerbated by the remarkable user-friendliness
                  of modern, mobile graphical interfaces, which, for example,
                  display visual feedback to improve the user experience and
                  make common tasks, \$\ensuremath{\backslash}backslash\$eg,
                  typing, more natural. Unfortunately, this turns into the
                  well-known trade-off between usability and security. In this
                  work, we focus on how usability of modern mobile interfaces
                  may affect the users' privacy. In particular, we describe a
                  practical eavesdropping attack, able to recognize the
                  sequence of keystrokes from a low-resolution video, recorded
                  while the victim is typing on a touchscreen. Our attack
                  exploits the fact that modern virtual keyboards, as opposed
                  to mechanical ones, often display magnified, virtual keys in
                  predictable positions. To demonstrate the feasibility of this
                  attack we implemented it against 2010's most popular
                  smart-phone (i.e., Apple's iPhone). Our approach works under
                  realistic conditions, because it tracks and rectifies the
                  target screen according to the victim's natural movements,
                  before performing the keystroke recognition. On real-world
                  settings, our attack can automatically recognize up to
                  97.07\% (91.03\% on average) of the keystrokes, with a 1.15\%
                  error rate and a speed between 37 and 51 keystrokes per
                  minute. This work confirms that touchscreen keyboards that
                  magnify keys make automatic eavesdropping attacks easier than
                  in classic mobile keyboards.},
  date          = {2010-11-01}
}

@InProceedings{   maggi_phonephishing_2010,
  shorttitle    = {PhonePhishing},
  author        = {Maggi, Federico},
  title         = {Are the {{Con Artists Back}}? {{A Preliminary Analysis}} of
                  {{Modern Phone Frauds}}},
  publisher     = {{IEEE Computer Society}},
  booktitle     = {Proceedings of the {{International Conference}} on
                  {{Computer}} and {{Information Technology}} ({{CIT}})},
  pages         = {824--831},
  abstract      = {Phishing is the practice of eliciting a person's
                  confidential information such as name, date of birth or
                  credit card details. Typically, the phishers use simple
                  technologies (e.g., e-mailing) to spread social engineering
                  attacks with the goal of persuading a large amount of victims
                  into voluntarily disclose sensitive data. Phishing based on
                  e-mail and web technologies is certainly the most popular
                  form. It has indeed received ample attention and some
                  mitigation measures have been implemented. In this paper we
                  describe our study on vishing (voice phishing), a form of
                  phishing where the scammers exploit the phone channel to ask
                  for sensitive information, rather than sending e-mails and
                  cloning trustworthy websites. In some sense, the traditional
                  ala-Mitnick phone scams are streamlined by attackers using
                  techniques that are typical of modern, e-mail-based phishing.
                  We detail our analysis of an embryonic, real-world database
                  of vishing attacks reported by victims through a
                  publicly-available web application that we build for this
                  purpose. The vishing activity that we registered in our
                  preliminary analysis is targeted against the U.S. customers.
                  According to our samples, we analyzed to what extent the
                  criminals rely on automated responders to streamline the
                  vishing campaigns. In addition, we analyzed the content of
                  the conversations and found that words such as ``credit'',
                  ``press'' (a key) or ``account'' are fairly popular. In
                  addition, we describe the data collection infrastructure and
                  motivate why gathering data about vishing is more difficult
                  than for regular e-mail phishing.},
  doi           = {10.1109/CIT.2010.156},
  isbn          = {978-0-7695-4108-2},
  date          = {2010-06-29}
}

@InProceedings{   maggi_traces_2010,
  shorttitle    = {Traces},
  author        = {Maggi, Federico},
  title         = {A {{Recognizer}} of {{Rational Trace Languages}}},
  publisher     = {{IEEE Computer Society}},
  booktitle     = {Proceedings of the {{International Conference}} on
                  {{Computer}} and {{Information Technology}} ({{CIT}})},
  pages         = {257--264},
  abstract      = {A one-pass recognition algorithm is presented to solve the
                  membership problem for rational trace languages. The
                  algorithm is detailed through the formal specification of the
                  Buffer Machine, a non-deterministic, finite-state automaton
                  with multiple buffers that can solve the membership problem
                  in polynomial time. The performances and characteristics of
                  the proposed solution are evaluated on a testbed
                  implementation using pseudo-random traces, strings, languages
                  and dependency relations.},
  doi           = {10.1109/CIT.2010.77},
  isbn          = {978-0-7695-4108-2},
  date          = {2010-06}
}

@InProceedings{   robertson_longtail_2010,
  shorttitle    = {LongTail},
  author        = {Robertson, William and Maggi, Federico and Kruegel,
                  Christopher and Vigna, Giovanni},
  title         = {Effective {{Anomaly Detection}} with {{Scarce Training
                  Data}}},
  publisher     = {{The Internet Society}},
  booktitle     = {Proceedings of the {{Network}} and {{Distributed System
                  Security Symposium}} ({{NDSS}})},
  abstract      = {Learning-based anomaly detection has proven to be an
                  effective black-box technique for detecting unknown attacks.
                  However, the effectiveness of this technique crucially
                  depends upon both the quality and the completeness of the
                  training data. Unfortunately, in most cases, the traffic to
                  the system (e.g., a web application or daemon process)
                  protected by an anomaly detector is not uniformly
                  distributed. Therefore, some components (e.g.,
                  authentication, payments, or content publishing) might not be
                  exercised enough to train an anomaly detection system in a
                  reasonable time frame. This is of particular importance in
                  real-world settings, where anomaly detection systems are
                  deployed with little or no manual configuration, and they are
                  expected to automatically learn the normal behavior of a
                  system to detect or block attacks. In this work, we first
                  demonstrate that the features utilized to train a
                  learning-based detector can be semantically grouped, and that
                  features of the same group tend to induce similar models.
                  Therefore, we propose addressing local training data
                  deficiencies by exploiting clustering techniques to construct
                  a knowledge base of well-trained models that can be utilized
                  in case of undertraining. Our approach, which is independent
                  of the particular type of anomaly detector employed, is
                  validated using the realistic case of a learning-based system
                  protecting a pool of web servers running several web
                  applications such as blogs, forums, or Web services. We run
                  our experiments on a real-world data set containing over 58
                  million HTTP requests to more than 36,000 distinct web
                  application components. The results show that by using the
                  proposed solution, it is possible to achieve effective attack
                  detection even with scarce training data.},
  doi           = {10.1.1.183.3323},
  date          = {2010-03-01}
}

@Unpublished{     maggi_phdthesisfbk_talk_2010,
  shorttitle    = {PhDThesisFBK},
  author        = {Maggi, Federico},
  title         = {Detecting {{Anomalous Behaviors}} in {{Computer
                  Infrastructures}}},
  location      = {{Fondazione Bruno Kessler, Trento}},
  date          = {2010-02-25},
  howpublished  = {Invited Talk}
}

@Unpublished{     maggi_justintime_talk_2010,
  shorttitle    = {JustInTime},
  author        = {Maggi, Federico},
  title         = {Just-in-{{Time Training}} of {{Anomaly Detectors}}},
  eventtitle    = {{Computer Systems Seminar}},
  location      = {{Vrije Universiteit, Amsterdam}},
  date          = {2010-01-21},
  howpublished  = {Invited Talk}
}

@PhDThesis{       maggi_phdthesis_2010,
  author        = {Maggi, Federico},
  title         = {Integrated {{Detection}} of {{Anomalous Behavior}} of
                  {{Computer Infrastructures}}},
  date          = {2010},
  shortitle     = {PhDThesis},
  location      = {{Milano, Italy}},
  url           = {https://github.com/phretor/cs-phd-dissertation-latex-template},
  abstract      = {This dissertation details our research on anomaly detection
                  techniques, that are central to several classic
                  security-related tasks such as network monitoring, but it
                  also have broader applications such as program behavior
                  characterization or malware classification. In particular, we
                  worked on anomaly detection from three different perspective,
                  with the common goal of recognizing awkward activity on
                  computer infrastructures. In fact, a computer system has
                  several weak spots that must be protected to avoid attackers
                  to take advantage of them. We focused on protecting the
                  operating system, central to any computer, to avoid malicious
                  code to subvert its normal activity. Secondly, we
                  concentrated on protecting the web applications, which can be
                  considered the modern, shared operating systems; because of
                  their immense popularity, they have indeed become the most
                  targeted entry point to violate a system. Last, we
                  experimented with novel techniques with the aim of
                  identifying related events (e.g., alerts reported by
                  intrusion detection systems) to build new and more compact
                  knowledge to detect malicious activity on large-scale
                  systems.
                  
                  Our contributions regarding host-based protection systems
                  focus on characterizing a process' behavior through the
                  system calls invoked into the kernel. In particular, we
                  engineered and carefully tested different versions of a
                  multi-model detection system using both stochastic and
                  deterministic models to capture the features of the system
                  calls during normal operation of the operating system.
                  Besides demonstrating the effectiveness of our approaches, we
                  confirmed that the use of finite-state, deterministic models
                  allow to detect deviations from the process' control flow
                  with the highest accuracy; however, our contribution combine
                  this effectiveness with advanced models for the system calls'
                  arguments resulting in a significantly decreased number of
                  false alarms.
                  
                  Our contributions regarding web-based protection systems
                  focus on advanced training procedures to enable learning
                  systems to perform well even in presence of changes in the
                  web application source code---particularly frequent in the
                  Web 2.0 era. We also addressed data scarcity issues that is a
                  real problem when deploying an anomaly detector to protect a
                  new, never-used-before application. Both these issues
                  dramatically decrease the detection capabilities of an
                  intrusion detection system but can be effectively mitigated
                  by adopting the techniques we propose.
                  
                  Last, we investigated the use of different stochastic and
                  fuzzy models to perform automatic alert correlation, which is
                  as post processing step to intrusion detection. We proposed a
                  fuzzy model that formally defines the errors that inevitably
                  occur if time-based alert aggregation (i.e., two alerts are
                  considered correlated if they are close in time) is used.
                  This model allow to account for measurements errors and avoid
                  false correlations due to delays, for instance, or incorrect
                  parameter settings. In addition, we defined a model to
                  describe the alert generation as a stochastic process and
                  experimented with non-parametric statistical tests to define
                  robust, zero-configuration correlation systems.
                  
                  The aforementioned tools have been tested over different
                  datasets---that are thoroughly documented in this
                  document---and lead to interesting results.},
  institution   = {{Politecnico di Milano}}
}

@InProceedings{   criscione_masibty_2009,
  shorttitle    = {Masibty},
  author        = {Criscione, Claudio and Maggi, Federico and Salvaneschi,
                  Guido and Zanero, Stefano},
  title         = {Integrated {{Detection}} of {{Attacks Against Browsers}},
                  {{Web Applications}} and {{Databases}}},
  publisher     = {{IEEE Computer Society}},
  booktitle     = {Proceedings of the {{European Conference}} on {{Network
                  Defense}} ({{EC2ND}})},
  abstract      = {Anomaly-based techniques were exploited successfully to
                  implement protection mechanisms for various systems.
                  Recently, these approaches have been ported to the web domain
                  under the name of ``web application anomaly detectors'' (or
                  firewalls) with promising results. In particular, those
                  capable of automatically building specifications, or models,
                  of the protected application by observing its traffic (e.g.,
                  network packets, system calls, or HTTP requests and
                  responses) are particularly interesting, since they can be
                  deployed with little effort. Typically, the detection
                  accuracy of these systems is significantly influenced by the
                  model building phase (often called training), which clearly
                  depends upon the quality of the observed traffic, which
                  should resemble the normal activity of the protected
                  application and must be also free from attacks. Otherwise,
                  detection may result in significant amounts of false
                  positives (i.e., benign events flagged as anomalous) and
                  negatives (i.e., undetected threats). In this work we
                  describe Masibty, a web application anomaly detector that
                  have some interesting properties. First, it requires the
                  training data not to be attack-free. Secondly, not only it
                  protects the monitored application, it also detects and
                  blocks malicious client-side threats before they are sent to
                  the browser. Third, Masibty intercepts the queries before
                  they are sent to the database, correlates them with the
                  corresponding HTTP requests and blocks those deemed
                  anomalous. Both the accuracy and the performance have been
                  evaluated on real-world web applications with interesting
                  results. The system is almost not influenced by the presence
                  of attacks in the training data and shows only a negligible
                  amount of false positives, although this is paid in terms of
                  a slight performance overhead.},
  doi           = {10.1109/EC2ND.2009.13},
  isbn          = {978-0-7695-3983-6},
  date          = {2009-11-09}
}

@Article{         maggi_fuzzyalertaggregation_article_2009,
  shorttitle    = {FuzzyAlertAggregation},
  author        = {Maggi, Federico and Matteucci, Matteo and Zanero, Stefano},
  title         = {Reducing false positives in anomaly detectors through fuzzy
                  alert aggregation},
  journaltitle  = {Information Fusion},
  volume        = {10},
  number        = {4},
  pages         = {300--311},
  abstract      = {In this paper we focus on the aggregation of IDS alerts, an
                  important component of the alert fusion process. We exploit
                  fuzzy measures and fuzzy sets to design simple and robust
                  alert aggregation algorithms. Exploiting fuzzy sets, we are
                  able to robustly state whether or not two alerts are ``close
                  in time'', dealing with noisy and delayed detections. A
                  performance metric for the evaluation of fusion systems is
                  also proposed. Finally, we evaluate the fusion method with
                  alert streams from anomaly-based IDS.},
  doi           = {10.1016/j.inffus.2009.01.004},
  issn          = {1566-2535},
  date          = {2009-10-01}
}

@InProceedings{   maggi_conceptdrift_2009,
  shorttitle    = {ConceptDrift},
  author        = {Maggi, Federico and Robertson, William and Kruegel,
                  Christopher and Vigna, Giovanni},
  title         = {Protecting a {{Moving Target}}: {{Addressing Web Application
                  Concept Drift}}},
  booktitle     = {Proceedings of the {{International Symposium}} on {{Recent
                  Advances}} in {{Intrusion Detection}} ({{RAID}})},
  abstract      = {Because of the ad hoc nature of web applications, intrusion
                  detection systems that leverage machine learning techniques
                  are particularly well-suited for protecting websites. The
                  reason is that these systems are able to characterize the
                  applications' normal behavior in an automated fashion.
                  However, anomaly-based detectors for web applications suffer
                  from false positives that are generated whenever the
                  applications being protected change. These false positives
                  need to be analyzed by the security officer who then has to
                  interact with the web application developers to confirm that
                  the reported alerts were indeed erroneous detections. In this
                  paper, we propose a novel technique for the automatic
                  detection of changes in web applications, which allows for
                  the selective retraining of the affected anomaly detection
                  models. We demonstrate that, by correctly identifying
                  legitimate changes in web applications, we can reduce false
                  positives and allow for the automated retraining of the
                  anomaly models. We have evaluated our approach by analyzing a
                  number of real-world applications. Our analysis shows that
                  web applications indeed change substantially over time, and
                  that our technique is able to effectively detect changes and
                  automatically adapt the anomaly detection models to the new
                  structure of the changed web applications.},
  doi           = {10.1007/978-3-642-04342-0_2},
  date          = {2009-09-23}
}

@InProceedings{   frossi_hybridsyscalls_2009,
  shorttitle    = {HybridSyscalls},
  author        = {Frossi, Alessandro and Maggi, Federico and Rizzo, Gian Luigi
                  and Zanero, Stefano},
  title         = {Selecting and {{Improving System Call Models}} for {{Anomaly
                  Detection}}},
  booktitle     = {Proceedings of the {{International Conference}} on
                  {{Detection}} of {{Intrusions}} and {{Malware}}, and
                  {{Vulnerability Assessment}} ({{DIMVA}})},
  abstract      = {We propose a syscall-based anomaly detection system that
                  incorporates both deterministic and stochastic models. We
                  analyze in detail two alternative approaches for anomaly
                  detection over system call sequences and arguments, and
                  propose a number of modifications that significantly improve
                  their performance. We begin by comparing them and analyzing
                  their respective performance in terms of detection accuracy.
                  Then, we outline their major shortcomings, and propose
                  various changes in the models that can address them: we show
                  how targeted modifications of their anomaly models, as
                  opposed to the redesign of the global system, can noticeably
                  improve the overall detection accuracy. Finally, the impact
                  of these modifications are discussed by comparing the
                  performance of the two original implementations with two
                  modified versions complemented with our models.},
  doi           = {10.1007/978-3-642-02918-9_13},
  date          = {2009-07-09}
}

@Article{         maggi_syscallseq_article_2008,
  shorttitle    = {SyscallSeq},
  author        = {Maggi, Federico and Matteucci, Matteo and Zanero, Stefano},
  title         = {Detecting {{Intrusions}} through {{System Call Sequence}}
                  and {{Argument Analysis}}},
  journaltitle  = {IEEE Transactions on Dependable and Secure Computing
                  (TODS)},
  volume        = {7},
  number        = {4},
  pages         = {381--395},
  abstract      = {We describe an unsupervised host-based intrusion detection
                  system based on system calls arguments and sequences. We
                  define a set of anomaly detection models for the individual
                  parameters of the call. We then describe a clustering process
                  which helps to better fit models to system call arguments,
                  and creates inter-relations among different arguments of a
                  system call. Finally, we add a behavioral Markov model in
                  order to capture time correlations and abnormal behaviors.
                  The whole system needs no prior knowledge input; it has a
                  good signal to noise ratio, and it is also able to correctly
                  contextualize alarms, giving the user more information to
                  understand whether a true or false positive happened, and to
                  detect variations over the entire execution flow, as opposed
                  to punctual variations over individual instances.},
  doi           = {10.1109/TDSC.2008.69},
  issn          = {1545-5971},
  date          = {2008-11-17}
}

@TechReport{      maggi_traces_tr_2008,
  shorttitle    = {Traces},
  author        = {Maggi, Federico},
  title         = {Specification and {{Evaluation}} of an {{Efficient
                  Recognizer}} for {{Rational Trace Languages}}},
  institution   = {{Politecnico di Milano}},
  number        = {2008-23},
  abstract      = {An improved, one-pass version of a two-pass, Earley-like
                  recognition algorithm is here proposed to solve the
                  Membership Problem for rational trace languages in polynomial
                  time. The algorithm is first described through the formal
                  specification of what we called a Non Deterministic Buffer
                  Machine (NDBM); secondly, the recognition is detailed through
                  a deterministic algorithm along with some running examples.
                  In addition, we describe our prototype implementation of the
                  algorithm used to empirically evaluate the performances and
                  the characteristics of the proposed solution. To this end, we
                  designed pseudo-random testing data generators that are here
                  described as well.},
  date          = {2008-06-01}
}

@Article{         maggi_antiforensics_article_2008,
  shorttitle    = {AntiForensics},
  author        = {Maggi, Federico and Zanero, Stefano and Iozzo, Vincenzo},
  title         = {Seeing the invisible: forensic uses of anomaly detection and
                  machine learning},
  journaltitle  = {Operating Systems Review of the ACM Special Interest Group
                  on Operating Systems (SIGOPS)},
  volume        = {42},
  number        = {3},
  pages         = {51--58},
  abstract      = {Anti-forensics is the practice of circumventing classical
                  forensics analysis procedures making them either unreliable
                  or impossible. In this paper we propose the use of machine
                  learning algorithms and anomaly detection to cope with a wide
                  class of definitive anti-forensics techniques. We test the
                  proposed system on a dataset we created through the
                  implementation of an innovative technique of anti-forensics,
                  and we show that our approach yields promising results in
                  terms of detection.},
  doi           = {10.1145/1368506.1368514},
  issn          = {0163-5980},
  date          = {2008-04-01}
}

@TechReport{      maggi_recordmatching_tr_2008,
  shorttitle    = {RecordMatching},
  author        = {Maggi, Federico},
  title         = {A {{Survey}} of {{Probabilistic Record Matching Models}},
                  {{Techniques}} and {{Tools}}},
  institution   = {{Politecnico di Milano}},
  number        = {2008-22},
  abstract      = {Probabilistic record linkage regards the use of stochastic
                  decision models to solve the problem of record linkage (also
                  known as record matching). Data quality has became a key
                  aspect in many institutions and the demand for novel,
                  effective techniques is increasing. Record linkage in general
                  has been studied in the last three decades and a solid
                  probabilistic decision framework has been proposed along with
                  several extensions and specific estimation methods. This
                  paper is a survey work narrowed to the most recent and
                  promising approaches also including a selection of data
                  cleansing tools based on probabilistic decision models.},
  date          = {2008-04-01}
}

@InProceedings{   maggi_alertcorrelation_2007,
  shorttitle    = {AlertCorrelation},
  author        = {Maggi, Federico and Zanero, Stefano},
  title         = {On the {{Use}} of {{Different Statistical Tests}} for
                  {{Alert Correlation}} - {{Short Paper}}},
  booktitle     = {Proceedings of the {{International Symposium}} on {{Recent
                  Advances}} in {{Intrusion Detection}} ({{RAID}})},
  pages         = {167--177},
  abstract      = {In this paper we analyze the use of different types of
                  statistical tests for the correlation of anomaly detection
                  alerts. We show that the Granger Causality Test, one of the
                  few proposals that can be extended to the anomaly detection
                  domain, strongly depends on good choices of a parameter which
                  proves to be both sensitive and difficult to estimate. We
                  propose a different approach based on a set of simpler
                  statistical tests, and we prove that our criteria work well
                  on a simplified correlation task, without requiring complex
                  configuration parameters.},
  doi           = {10.1007/978-3-540-74320-0_9},
  date          = {2007-09-05}
}
